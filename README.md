# Retail Pricing Management System# Retail Pricing Management System# Retail Pricing Management System# Retail Pricing Management System# Retail Pricing Management System# Retail Pricing Management System# Product Service - CSV Upload API



A multi-service web application for managing pricing feeds from 3000+ retail stores. Built with Angular, Go, and Python.



---A multi-service web application for managing pricing feeds from 3000+ retail stores. Built with Angular, Go, and Python.



## Context Diagram



The system allows retail store users to upload CSV files, search pricing data, and edit records through a modern web interface.---A scalable multi-service platform for managing pricing data from 3000+ retail stores across multiple countries. Built with Angular, Go, and Python.



```

                  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”

                  â”‚  Retail Store User  â”‚## Context Diagram

                  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

                             â”‚

                             â–¼

                  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”The system allows retail store users to upload CSV files, search pricing data, and edit records through a modern web interface.---A scalable, multi-service web application for managing and analyzing pricing feeds from retail stores across multiple countries. The system enables upload, persistence, search, and modification of pricing data from 3000+ retail stores.

                  â”‚   Angular Web UI    â”‚

                  â”‚  - Upload CSV       â”‚

                  â”‚  - Search & Filter  â”‚

                  â”‚  - Edit Records     â”‚```

                  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

                             â”‚ REST APIs                  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”

                             â–¼

                  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                  â”‚  Retail Store User  â”‚## ğŸ“‹ Table of Contents

                  â”‚  Backend Services   â”‚

                  â”‚                     â”‚                  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

                  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚

                  â”‚  â”‚ Python API     â”‚ â”‚                             â”‚

                  â”‚  â”‚ (FastAPI)      â”‚ â”‚

                  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚                             â–¼

                  â”‚                     â”‚

                  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚                  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”- [Overview](#overview)---A scalable, multi-service web application for managing and analyzing pricing feeds from retail stores across multiple countries. The system enables upload, persistence, search, and modification of pricing data from 3000+ retail stores.

                  â”‚  â”‚ Go Ingestion   â”‚ â”‚

                  â”‚  â”‚ (Gin)          â”‚ â”‚                  â”‚   Angular Web UI    â”‚

                  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚

                  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                  â”‚  - Upload CSV       â”‚- [Context Diagram](#context-diagram)

                             â”‚

           â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                  â”‚  - Search & Filter  â”‚

           â”‚                                   â”‚

           â–¼                                   â–¼                  â”‚  - Edit Records     â”‚- [Solution Architecture](#solution-architecture)

   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”

   â”‚  PostgreSQL   â”‚                  â”‚ S3 / Storage  â”‚                  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

   â”‚  - Records    â”‚                  â”‚ - CSV Files   â”‚

   â”‚  - Audit Logs â”‚                  â”‚ - Archives    â”‚                             â”‚ REST APIs- [Design Decisions](#design-decisions)

   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

```                             â–¼



**Key Components:**                  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”- [Non-Functional Requirements](#non-functional-requirements)## ğŸ“‹ Table of Contents

- **Users:** Store managers, pricing analysts, administrators

- **Frontend:** Single Page Application for all interactions                  â”‚  Backend Services   â”‚

- **Backend:** Separate services for file processing (Go) and data operations (Python)

- **Storage:** Relational database for records, object storage for files                  â”‚                     â”‚- [Assumptions](#assumptions)



---                  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚



## Solution Architecture                  â”‚  â”‚ Python API     â”‚ â”‚- [Getting Started](#getting-started)



The architecture uses an event-driven approach where file uploads are processed asynchronously.                  â”‚  â”‚ (FastAPI)      â”‚ â”‚



```                  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚

                  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”

                  â”‚   Angular UI     â”‚                  â”‚                     â”‚

                  â”‚  (Port: 4200)    â”‚

                  â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚---- [Overview](#overview)---A scalable, multi-service web application for managing and analyzing pricing feeds from retail stores across multiple countries. The system enables upload, persistence, search, and modification of pricing data from 3000+ retail stores.A microservice built with Go and the Gin web framework that provides an endpoint for uploading CSV files.

                           â”‚

          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                  â”‚  â”‚ Go Ingestion   â”‚ â”‚

          â”‚                                 â”‚

          â–¼                                 â–¼                  â”‚  â”‚ (Gin)          â”‚ â”‚

   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”             â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”

   â”‚  Python API     â”‚             â”‚  Go Ingestion    â”‚                  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚

   â”‚  (Port: 8000)   â”‚             â”‚  (Port: 8080)    â”‚

   â”‚                 â”‚             â”‚                  â”‚                  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜## ğŸ¯ Overview- [Context Diagram](#context-diagram)

   â”‚ â€¢ Presigned URL â”‚             â”‚ â€¢ Event Listener â”‚

   â”‚ â€¢ Search API    â”‚             â”‚ â€¢ CSV Validator  â”‚                             â”‚

   â”‚ â€¢ CRUD Ops      â”‚             â”‚ â€¢ Stream Parser  â”‚

   â”‚ â€¢ Auth          â”‚             â”‚ â€¢ Batch Insert   â”‚           â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”

   â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜             â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

            â”‚                               â”‚           â”‚                                   â”‚

            â”‚        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

            â”‚        â”‚  Storage Event           â–¼                                   â–¼**Retail Pricing Management System** enables retail chains to:- [Solution Architecture](#solution-architecture)

            â”‚        â”‚

   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”

   â”‚                  DATA LAYER                       â”‚

   â”‚                                                   â”‚   â”‚  PostgreSQL   â”‚                  â”‚ S3 / Storage  â”‚- Upload CSV pricing feeds (Store ID, SKU, Product Name, Price, Date)

   â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚

   â”‚  â”‚ S3 / Storage   â”‚         â”‚   PostgreSQL    â”‚  â”‚   â”‚  - Records    â”‚                  â”‚ - CSV Files   â”‚

   â”‚  â”‚ â€¢ CSV Upload   â”‚         â”‚ â€¢ Records       â”‚  â”‚

   â”‚  â”‚ â€¢ Event Triggerâ”‚         â”‚ â€¢ Upload Historyâ”‚  â”‚   â”‚  - Audit Logs â”‚                  â”‚ - Archives    â”‚- Search and filter pricing records- [Technology Stack](#technology-stack)

   â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚

   â”‚                                                   â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

   â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                             â”‚

   â”‚  â”‚ Redis (Cache)   â”‚                             â”‚```- Edit and update pricing data in real-time

   â”‚  â”‚ â€¢ Search Cache  â”‚                             â”‚

   â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                             â”‚

   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

```**Key Components:**- [Design Decisions](#design-decisions)## ğŸ“‹ Table of Contents



**Architecture Highlights:**- **Users:** Store managers, pricing analysts, administrators



1. **Python API Service (FastAPI)**- **Frontend:** Single Page Application for all interactions**Technology Stack:**

   - Generates presigned URLs for direct S3 uploads

   - Handles search queries with Redis caching- **Backend:** Separate services for file processing (Go) and data operations (Python)

   - Manages CRUD operations with PostgreSQL

   - Provides authentication and authorization- **Storage:** Relational database for records, object storage for files- **Frontend:** Angular 17+- [Non-Functional Requirements](#non-functional-requirements)



2. **Go Ingestion Service (Gin)**

   - Listens to S3 storage events

   - Validates and parses CSV files using streaming---- **Upload Service:** Go + Gin (This Repository)

   - Performs batch inserts to PostgreSQL

   - Efficient concurrent processing with goroutines



3. **Data Flow**## Solution Architecture- **Data API:** Python + FastAPI- [Assumptions](#assumptions)

   - **Upload:** User â†’ Angular â†’ Python API (Presigned URL) â†’ S3 â†’ Storage Event â†’ Go Service â†’ PostgreSQL

   - **Search:** User â†’ Angular â†’ Python API â†’ Redis (Cache) â†’ PostgreSQL

   - **Edit:** User â†’ Angular â†’ Python API â†’ PostgreSQL (Transaction) â†’ Audit Log

The architecture uses an event-driven approach where file uploads are processed asynchronously.- **Database:** PostgreSQL + Redis

**Key Design Decisions:**

- **Event-Driven:** Decouples upload from processing for better scalability

- **Direct S3 Upload:** Reduces backend load and improves upload performance

- **Streaming Parser:** Handles large CSV files efficiently without loading into memory```- **Storage:** S3 / Local FileSystem- [Getting Started](#getting-started)

- **Batch Inserts:** Optimizes database performance (1000 records per batch)

- **Microservices:** Go excels at I/O operations; Python excels at data manipulation                  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”


                  â”‚   Angular UI     â”‚

                  â”‚  (Port: 4200)    â”‚

                  â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜---- [Source Implementation](#source-implementation)- [Overview](#overview)---## Features

                           â”‚

          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”

          â”‚                                 â”‚

          â–¼                                 â–¼## ğŸ—ºï¸ Context Diagram

   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”             â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”

   â”‚  Python API     â”‚             â”‚  Go Ingestion    â”‚

   â”‚  (Port: 8000)   â”‚             â”‚  (Port: 8080)    â”‚

   â”‚                 â”‚             â”‚                  â”‚```---- [Context Diagram](#context-diagram)

   â”‚ â€¢ Presigned URL â”‚             â”‚ â€¢ Event Listener â”‚

   â”‚ â€¢ Search API    â”‚             â”‚ â€¢ CSV Validator  â”‚                  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”

   â”‚ â€¢ CRUD Ops      â”‚             â”‚ â€¢ Stream Parser  â”‚

   â”‚ â€¢ Auth          â”‚             â”‚ â€¢ Batch Insert   â”‚                  â”‚  Retail Store User  â”‚

   â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜             â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

            â”‚                               â”‚                  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

            â”‚        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

            â”‚        â”‚  Storage Event                             â”‚## ğŸ¯ Overview- [Solution Architecture](#solution-architecture)

            â”‚        â”‚

   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                             â–¼

   â”‚                  DATA LAYER                       â”‚

   â”‚                                                   â”‚                  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”

   â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚

   â”‚  â”‚ S3 / Storage   â”‚         â”‚   PostgreSQL    â”‚  â”‚                  â”‚   Angular Web UI    â”‚

   â”‚  â”‚ â€¢ CSV Upload   â”‚         â”‚ â€¢ Records       â”‚  â”‚

   â”‚  â”‚ â€¢ Event Triggerâ”‚         â”‚ â€¢ Upload Historyâ”‚  â”‚                  â”‚  - Upload CSV       â”‚This solution provides a comprehensive pricing management platform for retail chains operating 3000+ stores across multiple countries.- [Technology Stack](#technology-stack)

   â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚

   â”‚                                                   â”‚                  â”‚  - Search & Filter  â”‚

   â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                             â”‚

   â”‚  â”‚ Redis (Cache)   â”‚                             â”‚                  â”‚  - Edit Records     â”‚

   â”‚  â”‚ â€¢ Search Cache  â”‚                             â”‚

   â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                             â”‚                  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

```                             â”‚**Key Capabilities:**- [Functional Requirements](#functional-requirements)## ğŸ“‹ Table of Contents- CSV file upload via HTTP POST



**Architecture Highlights:**                             â–¼



1. **Python API Service (FastAPI)**                  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”- CSV pricing feed uploads from retail stores

   - Generates presigned URLs for direct S3 uploads

   - Handles search queries with Redis caching                  â”‚  Backend Services   â”‚

   - Manages CRUD operations with PostgreSQL

   - Provides authentication and authorization                  â”‚                     â”‚- Persistent storage of pricing records (Store ID, SKU, Product Name, Price, Date)- [Non-Functional Requirements](#non-functional-requirements)



2. **Go Ingestion Service (Gin)**                  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚

   - Listens to S3 storage events

   - Validates and parses CSV files using streaming                  â”‚  â”‚ Python API     â”‚ â”‚- Advanced search and filter capabilities

   - Performs batch inserts to PostgreSQL

   - Efficient concurrent processing with goroutines                  â”‚  â”‚ (FastAPI)      â”‚ â”‚



3. **Data Flow**                  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚- Real-time editing and updates to pricing records- [Design Decisions](#design-decisions)- File size validation (max 10MB)

   - **Upload:** User â†’ Angular â†’ Python API (Presigned URL) â†’ S3 â†’ Storage Event â†’ Go Service â†’ PostgreSQL

   - **Search:** User â†’ Angular â†’ Python API â†’ Redis (Cache) â†’ PostgreSQL                  â”‚                     â”‚

   - **Edit:** User â†’ Angular â†’ Python API â†’ PostgreSQL (Transaction) â†’ Audit Log

                  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚- Scalable architecture supporting multi-country operations

**Key Design Decisions:**

- **Event-Driven:** Decouples upload from processing for better scalability                  â”‚  â”‚ Go Ingestion   â”‚ â”‚

- **Direct S3 Upload:** Reduces backend load and improves upload performance

- **Streaming Parser:** Handles large CSV files efficiently without loading into memory                  â”‚  â”‚ (Gin)          â”‚ â”‚- [Assumptions](#assumptions)

- **Batch Inserts:** Optimizes database performance (1000 records per batch)

- **Microservices:** Go excels at I/O operations; Python excels at data manipulation                  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚



---                  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜**Technology Stack:**



## Quick Start                             â”‚



```powershell           â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”- **Frontend:** Angular (Single Page Application)- [Project Structure](#project-structure)- [Overview](#overview)- CSV format validation

# Start all services with Docker Compose

docker-compose up -d           â”‚                                   â”‚



# Access applications           â–¼                                   â–¼- **Backend:** Go (Upload/Ingestion Service) + Python (Data API Service)

# - Frontend: http://localhost:4200

# - Python API: http://localhost:8000   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”

# - Go Service: http://localhost:8080

```   â”‚  PostgreSQL   â”‚                  â”‚ S3 / Storage  â”‚- **Database:** PostgreSQL (Primary) + Redis (Cache)- [Getting Started](#getting-started)



---   â”‚  - Records    â”‚                  â”‚ - CSV Files   â”‚



## Repository   â”‚  - Audit Logs â”‚                  â”‚ - Archives    â”‚- **Storage:** S3/Local FileSystem (CSV Files)



**Project:** [Pricing_Management_System](https://github.com/RKShukla1997/Pricing_Management_System)     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

**Last Updated:** February 17, 2026

```- [API Documentation](#api-documentation)- [Context Diagram](#context-diagram)- File type validation (only .csv files)



------



## ğŸ—ï¸ Solution Architecture- [Deployment](#deployment)



```## ğŸ—ºï¸ Context Diagram

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”

â”‚                     PRESENTATION LAYER                      â”‚- [Solution Architecture](#solution-architecture)- Automatic file storage with timestamps

â”‚                                                             â”‚

â”‚                  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                       â”‚### High-Level System Context

â”‚                  â”‚   Angular UI     â”‚                       â”‚

â”‚                  â”‚  (Port: 4200)    â”‚                       â”‚---

â”‚                  â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                       â”‚

â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€-â”˜```

                          â”‚ HTTP/REST

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”- [Technology Stack](#technology-stack)- Health check endpoint

â”‚                   APPLICATION LAYER                         â”‚

â”‚                                                             â”‚                â”‚   Retail Store User    â”‚

â”‚    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚

â”‚    â”‚  Python API     â”‚              â”‚  Go Ingestion    â”‚   â”‚                â”‚  (Store Managers,      â”‚## ğŸ¯ Overview

â”‚    â”‚  (Port: 8000)   â”‚              â”‚  (Port: 8080)    â”‚   â”‚

â”‚    â”‚                 â”‚              â”‚                  â”‚   â”‚                â”‚   Pricing Analysts,    â”‚

â”‚    â”‚ â€¢ Presigned URL â”‚              â”‚ â€¢ Event Listener â”‚   â”‚

â”‚    â”‚ â€¢ Search API    â”‚              â”‚ â€¢ CSV Validator  â”‚   â”‚                â”‚   Administrators)      â”‚- [Functional Requirements](#functional-requirements)- JSON responses with proper error handling

â”‚    â”‚ â€¢ CRUD Ops      â”‚              â”‚ â€¢ Stream Parser  â”‚   â”‚

â”‚    â”‚ â€¢ Auth          â”‚              â”‚ â€¢ Batch Insert   â”‚   â”‚                â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”‚    â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜              â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚

â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€-â”˜                             â”‚This solution provides a comprehensive pricing management platform for retail chains operating 3000+ stores across multiple countries. The system handles:

              â”‚                               â”‚

              â”‚        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                             â”‚ HTTPS

              â”‚        â”‚  Storage Event

              â”‚        â”‚                             â–¼- [Non-Functional Requirements](#non-functional-requirements)- Built with Gin framework for high performance

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”

â”‚                       DATA LAYER                           â”‚                â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”

â”‚                                                            â”‚

â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚                â”‚     Angular Web UI     â”‚- **CSV pricing feed uploads** from retail stores

â”‚  â”‚   S3 / Storage     â”‚         â”‚    PostgreSQL      â”‚    â”‚

â”‚  â”‚                    â”‚         â”‚                    â”‚    â”‚                â”‚   (Single Page App)    â”‚

â”‚  â”‚  â€¢ CSV Upload      â”‚         â”‚  â€¢ pricing_records â”‚    â”‚

â”‚  â”‚  â€¢ Event Trigger   â”‚         â”‚  â€¢ upload_history  â”‚    â”‚                â”‚                        â”‚- **Persistent storage** of pricing records (Store ID, SKU, Product Name, Price, Date)- [Design Decisions](#design-decisions)

â”‚  â”‚  â€¢ File Archive    â”‚         â”‚  â€¢ audit_logs      â”‚    â”‚

â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚                â”‚ - Upload Interface     â”‚

â”‚                                                            â”‚

â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                    â”‚                â”‚ - Search & Filter      â”‚- **Advanced search capabilities** with multiple criteria

â”‚  â”‚   Redis (Cache)    â”‚                                    â”‚

â”‚  â”‚  â€¢ Session         â”‚                                    â”‚                â”‚ - Edit Data Grid       â”‚

â”‚  â”‚  â€¢ Search Cache    â”‚                                    â”‚

â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                    â”‚                â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜- **Real-time editing** and updates to pricing records- [Assumptions](#assumptions)## Prerequisites

â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

```                             â”‚



### Data Flow                             â”‚ REST APIs- **Scalable architecture** supporting multi-country operations



**Upload Flow:**                             â”‚ (JSON)

```

User â†’ Angular â†’ Python API (Presigned URL) â†’ S3 Direct Upload                             â–¼- [Project Structure](#project-structure)

â†’ Storage Event â†’ Go Service â†’ Validate & Parse â†’ PostgreSQL

```                â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”



**Search Flow:**                â”‚   Backend Services     â”‚---

```

User â†’ Angular â†’ Python API â†’ Redis (Check Cache) â†’ PostgreSQL                â”‚                        â”‚

â†’ Cache Results â†’ Return to UI

```                â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚- [Getting Started](#getting-started)- Go 1.25.1 or higher



**Edit Flow:**                â”‚ â”‚  Python API Svc    â”‚ â”‚

```

User â†’ Angular â†’ Python API â†’ PostgreSQL (Transaction: Update + Audit)                â”‚ â”‚  (FastAPI)         â”‚ â”‚## ğŸ—ºï¸ Context Diagram

â†’ Invalidate Cache â†’ Return Updated Record

```                â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚



---                â”‚                        â”‚- [API Documentation](#api-documentation)- Git



## ğŸ¨ Design Decisions                â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚



### 1. Microservices with Language Optimization                â”‚ â”‚ Go Ingestion Svc   â”‚ â”‚### High-Level System Context



**Go for Upload/Ingestion:**                â”‚ â”‚ (Gin Framework)    â”‚ â”‚

- Excellent I/O performance

- Efficient memory management                â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚- [Deployment](#deployment)

- Native concurrency (goroutines)

- Fast CSV streaming                â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜



**Python for Data API:**                             â”‚```

- Rich data manipulation (Pandas, SQLAlchemy)

- Rapid API development (FastAPI)          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”

- Better for business logic

          â”‚                                     â”‚                â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”## Installation

### 2. Event-Driven Upload

          â–¼                                     â–¼

**Presigned URL + Storage Events:**

- Frontend uploads directly to S3 (no backend bottleneck) â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”               â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                â”‚   Retail Store User    â”‚

- S3 event triggers async processing

- Reduced bandwidth costs â”‚ Relational Databaseâ”‚               â”‚ Object Storage     â”‚

- Better scalability

 â”‚   (PostgreSQL)     â”‚               â”‚   (S3 / Local)     â”‚                â”‚  (Store Managers,      â”‚---

### 3. Streaming CSV Parser

 â”‚                    â”‚               â”‚                    â”‚

**Why:** Memory-efficient processing of large files

```go â”‚ - Pricing Records  â”‚               â”‚ - CSV Files        â”‚                â”‚   Pricing Analysts,    â”‚

reader := csv.NewReader(file)

for { â”‚ - Audit Logs       â”‚               â”‚ - File Archive     â”‚

    record, err := reader.Read()

    if err == io.EOF { break } â”‚ - User Sessions    â”‚               â”‚ - Backups          â”‚                â”‚   Administrators)      â”‚1. Clone the repository

    processBatch(record)

} â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜               â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

```

```                â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

### 4. PostgreSQL Database



**Why:** ACID compliance, complex queries, data integrity, proven at scale

---                             â”‚## ğŸ¯ Overview2. Install dependencies:

### 5. Batch Inserts



**Why:** 10-100x faster than individual inserts

```go## ğŸ—ï¸ Solution Architecture                             â”‚ HTTPS

const batchSize = 1000

for i := 0; i < len(records); i += batchSize {

    batch := records[i:min(i+batchSize, len(records))]

    db.BatchInsert(batch)### Detailed Architecture with Data Flow                             â–¼```bash

}

```



### 6. Optimistic Locking```                â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”



**Why:** Better concurrency, no database locksâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”

```python

UPDATE pricing_recordsâ”‚                         PRESENTATION LAYER                       â”‚                â”‚     Angular Web UI     â”‚This solution provides a comprehensive pricing management platform for retail chains operating 3000+ stores across multiple countries. The system handles:go mod download

SET price = $1, version = version + 1

WHERE id = $2 AND version = $3â”‚                                                                  â”‚

```

â”‚                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                        â”‚                â”‚   (Single Page App)    â”‚

---

â”‚                    â”‚     Angular UI     â”‚                        â”‚

## ğŸš€ Non-Functional Requirements

â”‚                    â”‚  (Port: 4200)      â”‚                        â”‚                â”‚                        â”‚```

### Performance

- **Search Response:** < 2 secondsâ”‚                    â”‚                    â”‚                        â”‚

- **Upload Speed:** 10MB file in < 5 seconds

- **Concurrent Users:** 1000+â”‚                    â”‚ - Material Design  â”‚                        â”‚                â”‚ - Upload Interface     â”‚

- **Throughput:** 100+ uploads/minute

â”‚                    â”‚ - State Management â”‚                        â”‚

**Approach:** DB indexing, Redis caching, connection pooling, async processing

â”‚                    â”‚ - Form Validation  â”‚                        â”‚                â”‚ - Search & Filter      â”‚- **CSV pricing feed uploads** from retail stores

### Scalability

- **Data Volume:** 100M+ recordsâ”‚                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                        â”‚

- **Store Growth:** 3000 â†’ 10,000 stores

- **Multi-Region:** Geographic distributionâ””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                â”‚ - Edit Data Grid       â”‚



**Approach:** Microservices, DB sharding, read replicas, auto-scaling, message queues                               â”‚



### Availability                               â”‚ HTTP/REST                â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜- **Persistent storage** of pricing records (Store ID, SKU, Product Name, Price, Date)## Running the Service

- **Uptime:** 99.9% (< 8.76 hours downtime/year)

- **Recovery:** RTO < 4 hours, RPO < 1 hour                               â”‚



**Approach:** Multi-AZ deployment, DB replication, health checks, daily backupsâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                             â”‚



### Securityâ”‚                       APPLICATION LAYER                          â”‚

- **Auth:** OAuth 2.0 / JWT

- **Encryption:** TLS 1.3, AES-256â”‚                               â”‚                                  â”‚                             â”‚ REST APIs- **Advanced search capabilities** with multiple criteria

- **Compliance:** GDPR, SOC 2

â”‚     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”       â”‚

**Approach:** API gateway, JWT tokens, encrypted connections, input validation, audit logs

â”‚     â”‚                                                     â”‚       â”‚                             â”‚ (JSON)

### Maintainability

- **Test Coverage:** > 80%â”‚     â–¼                                                     â–¼       â”‚

- **Documentation:** API docs, architecture diagrams

â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚                             â–¼- **Real-time editing** and updates to pricing records```bash

**Approach:** Unit/integration tests, OpenAPI/Swagger, CI/CD pipelines

â”‚ â”‚  Python API Serviceâ”‚                       â”‚ Go Ingestion   â”‚ â”‚

---

â”‚ â”‚  (FastAPI)         â”‚                       â”‚ Service (Gin)  â”‚ â”‚                â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”

## ğŸ“ Assumptions

â”‚ â”‚  Port: 8000        â”‚                       â”‚ Port: 8080     â”‚ â”‚

### Business

- 3000 stores â†’ 10,000 in 3 yearsâ”‚ â”‚                    â”‚                       â”‚                â”‚ â”‚                â”‚   Backend Services     â”‚- **Scalable architecture** supporting multi-country operationsgo run main.go

- Daily uploads per store

- Files: 1K-10K records (< 10MB)â”‚ â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚                       â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚ â”‚

- 2-year data retention

- 500 concurrent usersâ”‚ â”‚ â”‚ Generate       â”‚ â”‚                       â”‚ â”‚ Event      â”‚ â”‚ â”‚                â”‚                        â”‚



### Technicalâ”‚ â”‚ â”‚ Presigned URL  â”‚ â”‚                       â”‚ â”‚ Listener   â”‚ â”‚ â”‚

- 1 Mbps minimum upload speed

- Modern browsers (last 2 versions)â”‚ â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚                       â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚ â”‚                â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚```

- Database: 50GB â†’ 500GB

- Cloud-hosted (AWS/Azure/GCP)â”‚ â”‚                    â”‚                       â”‚                â”‚ â”‚



### Dataâ”‚ â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚                       â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚ â”‚                â”‚ â”‚  Python API Svc    â”‚ â”‚

- CSV format: `Store ID, SKU, Product Name, Price, Date`

- UTF-8 encodingâ”‚ â”‚ â”‚ Search API     â”‚ â”‚                       â”‚ â”‚ CSV        â”‚ â”‚ â”‚

- All fields required

- Price: 0.01 - 999,999.99â”‚ â”‚ â”‚ (Multi-Criteria)â”‚ â”‚                      â”‚ â”‚ Validation â”‚ â”‚ â”‚                â”‚ â”‚  (FastAPI)         â”‚ â”‚---

- Date: YYYY-MM-DD format

â”‚ â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚                       â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚ â”‚

### Security

- Corporate SSO (OAuth 2.0)â”‚ â”‚                    â”‚                       â”‚                â”‚ â”‚                â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚

- Three roles: Store Manager, Analyst, Admin

- VPN or whitelisted IPsâ”‚ â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚                       â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚ â”‚

- PCI DSS, GDPR compliance

â”‚ â”‚ â”‚ Update/Edit    â”‚ â”‚                       â”‚ â”‚ Streaming  â”‚ â”‚ â”‚                â”‚                        â”‚The server will start on port 8080 by default. You can change the port by setting the `PORT` environment variable:

### Operational

- 24/7 monitoringâ”‚ â”‚ â”‚ API (CRUD)     â”‚ â”‚                       â”‚ â”‚ Parser     â”‚ â”‚ â”‚

- Daily backups (30-day retention)

- Monthly maintenance windowsâ”‚ â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚                       â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚ â”‚                â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚

- 99.9% SLA

â”‚ â”‚                    â”‚                       â”‚                â”‚ â”‚

---

â”‚ â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚                       â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚ â”‚                â”‚ â”‚ Go Ingestion Svc   â”‚ â”‚## ğŸ—ºï¸ Context Diagram

## ğŸš€ Getting Started

â”‚ â”‚ â”‚ Authentication â”‚ â”‚                       â”‚ â”‚ DB Batch   â”‚ â”‚ â”‚

### Quick Start (Docker Compose)

â”‚ â”‚ â”‚ & Authorizationâ”‚ â”‚                       â”‚ â”‚ Insert     â”‚ â”‚ â”‚                â”‚ â”‚ (Gin Framework)    â”‚ â”‚

```powershell

# Start all servicesâ”‚ â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚                       â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚ â”‚

docker-compose up -d

â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                       â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚                â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚```bash

# View logs

docker-compose logs -fâ”‚           â”‚                                           â”‚         â”‚



# Stop servicesâ””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

docker-compose down

```            â”‚                                           â”‚



**Services:**            â”‚              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                             â”‚```# Windows PowerShell

- Angular: http://localhost:4200

- Python API: http://localhost:8000            â”‚              â”‚

- Go Ingestion: http://localhost:8080

            â”‚              â”‚     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”

### Manual Setup - Go Service

            â”‚              â”‚     â”‚ Storage Event Triggerâ”‚

```powershell

# Clone repository            â”‚              â”‚     â”‚ (S3 Event / Watcher) â”‚          â”‚                                     â”‚â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”$env:PORT="3000"; go run main.go

git clone https://github.com/RKShukla1997/Pricing_Management_System.git

cd golang-project-product-service            â”‚              â”‚     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜



# Install dependencies            â”‚              â”‚                â”‚          â–¼                                     â–¼

go mod download

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”

# Configure environment

cp .env.example .envâ”‚           â”‚       DATA LAYER              â”‚                       â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”               â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”â”‚                     External Actors                               â”‚



# Run serviceâ”‚           â”‚              â”‚                â”‚                       â”‚

go run cmd/server/main.go

```â”‚           â–¼              â–¼                â–¼                       â”‚ â”‚ Relational Databaseâ”‚               â”‚ Object Storage     â”‚



### Test Uploadâ”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”             â”‚



```powershellâ”‚  â”‚         Object Storage (S3 / Local FS)          â”‚             â”‚ â”‚   (PostgreSQL)     â”‚               â”‚   (S3 / Local)     â”‚â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤# Linux/Mac

# Create test CSV

@"â”‚  â”‚                                                  â”‚             â”‚

Store ID,SKU,Product Name,Price,Date

ST001,SKU12345,Laptop,999.99,2026-02-17â”‚  â”‚  1. User uploads CSV via UI                     â”‚             â”‚ â”‚                    â”‚               â”‚                    â”‚

ST001,SKU12346,Mouse,29.99,2026-02-17

"@ | Out-File -FilePath test.csv -Encoding utf8â”‚  â”‚  2. Python API generates presigned URL          â”‚             â”‚



# Uploadâ”‚  â”‚  3. Direct upload to S3 from browser            â”‚             â”‚ â”‚ - Pricing Records  â”‚               â”‚ - CSV Files        â”‚â”‚  ğŸ‘¤ Store Managers  â”‚  ğŸ‘¤ Pricing Analysts  â”‚  ğŸ‘¤ Administrators â”‚PORT=3000 go run main.go

Invoke-WebRequest -Uri "http://localhost:8080/upload" `

    -Method Post -Form @{file = Get-Item -Path "test.csv"}â”‚  â”‚  4. S3 event triggers Go Ingestion Service      â”‚             â”‚

```

â”‚  â”‚  5. File stored with metadata                   â”‚             â”‚ â”‚ - Audit Logs       â”‚               â”‚ - File Archive     â”‚

**Response:**

```jsonâ”‚  â”‚                                                  â”‚             â”‚

{

  "message": "File uploaded successfully",â”‚  â”‚  Structure: /uploads/YYYY/MM/DD/filename.csv    â”‚             â”‚ â”‚ - User Sessions    â”‚               â”‚ - Backups          â”‚â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜```

  "filename": "1708171234_test.csv",

  "size": 128,â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜             â”‚

  "rows": 3,

  "columns": 5â”‚                                                                   â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜               â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

}

```â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”            â”‚



---â”‚  â”‚      Relational Database (PostgreSQL)            â”‚            â”‚```               â”‚                   â”‚                 â”‚



## ğŸ“¦ Repository Structureâ”‚  â”‚                                                   â”‚            â”‚



```â”‚  â”‚  Tables:                                          â”‚            â”‚

golang-project-product-service/

â”œâ”€â”€ cmd/server/main.go           # Entry pointâ”‚  â”‚  â”œâ”€ pricing_records                              â”‚            â”‚

â”œâ”€â”€ internal/

â”‚   â”œâ”€â”€ handlers/                # HTTP handlersâ”‚  â”‚  â”‚  â”œâ”€ id (PK)                                   â”‚            â”‚### System Boundaries               â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜## API Endpoints

â”‚   â”œâ”€â”€ middleware/              # Auth, CORS, logging

â”‚   â”œâ”€â”€ models/                  # Data modelsâ”‚  â”‚  â”‚  â”œâ”€ store_id (Indexed)                        â”‚            â”‚

â”‚   â”œâ”€â”€ services/                # Business logic

â”‚   â””â”€â”€ config/                  # Configurationâ”‚  â”‚  â”‚  â”œâ”€ sku (Indexed)                             â”‚            â”‚

â”œâ”€â”€ pkg/utils/                   # Utilities

â”œâ”€â”€ uploads/                     # Temporary storageâ”‚  â”‚  â”‚  â”œâ”€ product_name                              â”‚            â”‚

â”œâ”€â”€ tests/                       # Unit & integration tests

â”œâ”€â”€ go.modâ”‚  â”‚  â”‚  â”œâ”€ price                                     â”‚            â”‚- **External Actors:** Store managers, pricing analysts, administrators                                   â”‚

â”œâ”€â”€ Dockerfile

â””â”€â”€ README.mdâ”‚  â”‚  â”‚  â”œâ”€ date (Indexed)                            â”‚            â”‚

```

â”‚  â”‚  â”‚  â”œâ”€ created_at                                â”‚            â”‚- **System Boundary:** Web UI + Backend Services + Data Stores

---

â”‚  â”‚  â”‚  â””â”€ updated_at                                â”‚            â”‚

## ğŸ§ª Testing

â”‚  â”‚  â”‚                                                â”‚            â”‚- **External Systems:** Corporate SSO, Monitoring Systems, Backup Services                                   â–¼### 1. Upload CSV File

```powershell

# Run all testsâ”‚  â”‚  â”œâ”€ upload_history                               â”‚            â”‚

go test ./... -v

â”‚  â”‚  â”‚  â”œâ”€ id (PK)                                   â”‚            â”‚

# With coverage

go test ./... -v -cover -coverprofile=coverage.outâ”‚  â”‚  â”‚  â”œâ”€ filename                                  â”‚            â”‚



# View coverageâ”‚  â”‚  â”‚  â”œâ”€ upload_date                               â”‚            â”‚---        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”

go tool cover -html=coverage.out

```â”‚  â”‚  â”‚  â”œâ”€ status                                    â”‚            â”‚



---â”‚  â”‚  â”‚  â”œâ”€ records_count                             â”‚            â”‚



## ğŸš¢ Deploymentâ”‚  â”‚  â”‚  â””â”€ user_id                                   â”‚            â”‚



### Dockerâ”‚  â”‚  â”‚                                                â”‚            â”‚## ğŸ—ï¸ Solution Architecture        â”‚        Angular Frontend (SPA)                     â”‚**Endpoint:** `POST /upload`

```powershell

docker build -t go-ingestion:latest .â”‚  â”‚  â””â”€ audit_logs                                   â”‚            â”‚

docker run -d -p 8080:8080 go-ingestion:latest

```â”‚  â”‚     â”œâ”€ id (PK)                                   â”‚            â”‚



### Kubernetesâ”‚  â”‚     â”œâ”€ table_name                                â”‚            â”‚

```powershell

kubectl apply -f k8s/deployment.yamlâ”‚  â”‚     â”œâ”€ record_id                                 â”‚            â”‚### Detailed Architecture with Data Flow        â”‚  - File Upload Interface                          â”‚

kubectl scale deployment go-ingestion --replicas=3

```â”‚  â”‚     â”œâ”€ action (INSERT/UPDATE/DELETE)             â”‚            â”‚



---â”‚  â”‚     â”œâ”€ old_value                                 â”‚            â”‚



## ğŸ”— Related Repositoriesâ”‚  â”‚     â”œâ”€ new_value                                 â”‚            â”‚



- [Angular Frontend](https://github.com/RKShukla1997/frontend)â”‚  â”‚     â”œâ”€ user_id                                   â”‚            â”‚```        â”‚  - Search & Filter UI                             â”‚**Content-Type:** `multipart/form-data`

- [Python Data Service](https://github.com/RKShukla1997/data-service)

- [Infrastructure (K8s/Terraform)](https://github.com/RKShukla1997/infrastructure)â”‚  â”‚     â””â”€ timestamp                                 â”‚            â”‚



---â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜            â”‚â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”



## ğŸ“„ Licenseâ”‚                                                                   â”‚



MIT Licenseâ”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”            â”‚â”‚                         PRESENTATION LAYER                       â”‚        â”‚  - Data Grid with Edit Capabilities               â”‚



---â”‚  â”‚           Cache Layer (Redis) - Optional         â”‚            â”‚



**Repository:** [Pricing_Management_System](https://github.com/RKShukla1997/Pricing_Management_System)  â”‚  â”‚                                                   â”‚            â”‚â”‚                                                                  â”‚

**Last Updated:** February 17, 2026

â”‚  â”‚  - Session Storage                                â”‚            â”‚

â”‚  â”‚  - Search Results Cache                           â”‚            â”‚â”‚                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                        â”‚        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜**Parameters:**

â”‚  â”‚  - Rate Limiting                                  â”‚            â”‚

â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜            â”‚â”‚                    â”‚     Angular UI     â”‚                        â”‚

â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

```â”‚                    â”‚  (Port: 4200)      â”‚                        â”‚                         â”‚              â”‚- `file`: CSV file (required)



### Data Flow Sequencesâ”‚                    â”‚                    â”‚                        â”‚



#### Upload Flowâ”‚                    â”‚ - Material Design  â”‚                        â”‚                â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”˜              â””â”€â”€â”€â”€â”€â”€â”€â”€â”

```

1. User â†’ Angular UI: Select CSV fileâ”‚                    â”‚ - State Management â”‚                        â”‚

2. Angular â†’ Python API: Request presigned URL

3. Python API â†’ S3: Generate presigned URLâ”‚                    â”‚ - Form Validation  â”‚                        â”‚                â”‚                                 â”‚**Example using curl:**

4. Python API â†’ Angular: Return presigned URL

5. Angular â†’ S3: Direct upload using presigned URLâ”‚                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                        â”‚

6. S3 â†’ Event Trigger: File upload complete event

7. Event Trigger â†’ Go Ingestion Svc: Trigger processingâ””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                â–¼                                 â–¼```bash

8. Go Ingestion Svc â†’ S3: Download and stream file

9. Go Ingestion Svc: Validate CSV structure                               â”‚

10. Go Ingestion Svc: Parse CSV (streaming)

11. Go Ingestion Svc â†’ PostgreSQL: Batch insert records                               â”‚ HTTP/REST    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”curl -X POST http://localhost:8080/upload -F "file=@data.csv"

12. Go Ingestion Svc â†’ PostgreSQL: Update upload_history

13. PostgreSQL â†’ Python API: Notify completion                               â”‚

14. Python API â†’ Angular: Push notification (WebSocket)

15. Angular: Display success messageâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚  Go Upload Service    â”‚       â”‚  Python Data Service    â”‚```

```

â”‚                       APPLICATION LAYER                          â”‚

#### Search Flow

```â”‚                               â”‚                                  â”‚    â”‚  (Port: 8080)         â”‚       â”‚  (Port: 8000)           â”‚

1. User â†’ Angular UI: Enter search criteria

2. Angular â†’ Python API: POST /api/v1/pricing/searchâ”‚     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”       â”‚

3. Python API â†’ Redis: Check cache

4. Redis â†’ Python API: Cache missâ”‚     â”‚                                                     â”‚       â”‚    â”‚  - CSV Upload         â”‚       â”‚  - Search/Query         â”‚**Example using PowerShell:**

5. Python API â†’ PostgreSQL: Execute search query

6. PostgreSQL â†’ Python API: Return resultsâ”‚     â–¼                                                     â–¼       â”‚

7. Python API â†’ Redis: Store in cache

8. Python API â†’ Angular: Return JSON responseâ”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚    â”‚  - Validation         â”‚       â”‚  - CRUD Operations      â”‚```powershell

9. Angular: Display results in data grid

```â”‚ â”‚  Python API Serviceâ”‚                       â”‚ Go Ingestion   â”‚ â”‚



#### Edit Flowâ”‚ â”‚  (FastAPI)         â”‚                       â”‚ Service (Gin)  â”‚ â”‚    â”‚  - File Persistence   â”‚       â”‚  - Data Processing      â”‚$uri = "http://localhost:8080/upload"

```

1. User â†’ Angular UI: Edit pricing record inlineâ”‚ â”‚  Port: 8000        â”‚                       â”‚ Port: 8080     â”‚ â”‚

2. Angular â†’ Python API: PUT /api/v1/pricing/{id}

3. Python API: Validate changesâ”‚ â”‚                    â”‚                       â”‚                â”‚ â”‚    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜$filePath = "C:\path\to\your\file.csv"

4. Python API â†’ PostgreSQL: Begin transaction

5. Python API â†’ PostgreSQL: Update pricing_recordâ”‚ â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚                       â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚ â”‚

6. Python API â†’ PostgreSQL: Insert audit_log

7. Python API â†’ PostgreSQL: Commit transactionâ”‚ â”‚ â”‚ Generate       â”‚ â”‚                       â”‚ â”‚ Event      â”‚ â”‚ â”‚               â”‚                                 â”‚$form = @{

8. PostgreSQL â†’ Python API: Confirm update

9. Python API â†’ Redis: Invalidate cacheâ”‚ â”‚ â”‚ Presigned URL  â”‚ â”‚                       â”‚ â”‚ Listener   â”‚ â”‚ â”‚

10. Python API â†’ Angular: Return updated record

11. Angular: Update UI with new valuesâ”‚ â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚                       â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚ â”‚               â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    file = Get-Item -Path $filePath

```

â”‚ â”‚                    â”‚                       â”‚                â”‚ â”‚

---

â”‚ â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚                       â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚ â”‚                            â”‚}

## ğŸ› ï¸ Technology Stack

â”‚ â”‚ â”‚ Search API     â”‚ â”‚                       â”‚ â”‚ CSV        â”‚ â”‚ â”‚

### Frontend

- **Framework:** Angular 17+â”‚ â”‚ â”‚ (Multi-Criteria)â”‚ â”‚                      â”‚ â”‚ Validation â”‚ â”‚ â”‚                            â–¼Invoke-RestMethod -Uri $uri -Method Post -Form $form

- **UI Library:** Angular Material / PrimeNG

- **State Management:** NgRx / Akitaâ”‚ â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚                       â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚ â”‚

- **HTTP Client:** Angular HttpClient

- **Form Validation:** Reactive Formsâ”‚ â”‚                    â”‚                       â”‚                â”‚ â”‚              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”```



### Backend Servicesâ”‚ â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚                       â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚ â”‚



#### Python API Service (Data Operations)â”‚ â”‚ â”‚ Update/Edit    â”‚ â”‚                       â”‚ â”‚ Streaming  â”‚ â”‚ â”‚              â”‚   Database Layer         â”‚

- **Language:** Python 3.11+

- **Framework:** FastAPIâ”‚ â”‚ â”‚ API (CRUD)     â”‚ â”‚                       â”‚ â”‚ Parser     â”‚ â”‚ â”‚

- **ORM:** SQLAlchemy

- **Data Processing:** Pandasâ”‚ â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚                       â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚ â”‚              â”‚   - PostgreSQL (Primary) â”‚**Success Response (200 OK):**

- **Validation:** Pydantic

- **Responsibilities:**â”‚ â”‚                    â”‚                       â”‚                â”‚ â”‚

  - Generate presigned URLs for S3 uploads

  - Search and filter pricing recordsâ”‚ â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚                       â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚ â”‚              â”‚   - Redis (Cache)        â”‚```json

  - CRUD operations on pricing data

  - User authentication and authorizationâ”‚ â”‚ â”‚ Authentication â”‚ â”‚                       â”‚ â”‚ DB Batch   â”‚ â”‚ â”‚



#### Go Ingestion Service (File Processing)â”‚ â”‚ â”‚ & Authorizationâ”‚ â”‚                       â”‚ â”‚ Insert     â”‚ â”‚ â”‚              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜{

- **Language:** Go 1.25+

- **Framework:** Gin Web Frameworkâ”‚ â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚                       â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚ â”‚

- **CSV Processing:** encoding/csv (streaming)

- **Concurrency:** Goroutinesâ”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                       â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚                            â”‚  "message": "File uploaded successfully",

- **Responsibilities:**

  - Listen to S3 storage eventsâ”‚           â”‚                                           â”‚         â”‚

  - Validate CSV file structure

  - Stream and parse large CSV filesâ””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                            â–¼  "filename": "1739151234_data.csv",

  - Batch insert records into database

            â”‚                                           â”‚

### Data Layer

- **Primary Database:** PostgreSQL 15+            â”‚              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  "size": 1024,

- **Cache:** Redis 7+ (Optional)

- **Object Storage:** AWS S3 / Azure Blob / Local FileSystem            â”‚              â”‚



### DevOps            â”‚              â”‚     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”              â”‚   Storage Layer          â”‚  "rows": 100,

- **Containerization:** Docker

- **Orchestration:** Kubernetes / Docker Compose            â”‚              â”‚     â”‚ Storage Event Triggerâ”‚

- **CI/CD:** GitHub Actions / GitLab CI

- **Monitoring:** Prometheus + Grafana            â”‚              â”‚     â”‚ (S3 Event / Watcher) â”‚              â”‚   - S3/Blob Storage      â”‚  "columns": 5

- **Logging:** ELK Stack

            â”‚              â”‚     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

---

            â”‚              â”‚                â”‚              â”‚   - File Archive         â”‚}

## ğŸ¨ Design Decisions

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”

### 1. Microservices Architecture with Language Optimization

â”‚           â”‚       DATA LAYER              â”‚                       â”‚              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜```

**Decision:** Use Go for ingestion and Python for API operations

â”‚           â”‚              â”‚                â”‚                       â”‚

**Rationale:**

- **Go for File Processing:**â”‚           â–¼              â–¼                â–¼                       â”‚```

  - Superior performance for I/O operations

  - Efficient memory management for large filesâ”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”             â”‚

  - Native goroutines for concurrent processing

  - Fast CSV parsing with streamingâ”‚  â”‚         Object Storage (S3 / Local FS)          â”‚             â”‚**Error Responses:**

  - Single binary deployment

  â”‚  â”‚                                                  â”‚             â”‚

- **Python for Data Operations:**

  - Rich ecosystem for data manipulation (Pandas)â”‚  â”‚  1. User uploads CSV via UI                     â”‚             â”‚---- `400 Bad Request`: File too large, invalid CSV format, or not a CSV file

  - FastAPI for rapid API development

  - SQLAlchemy for complex queriesâ”‚  â”‚  2. Python API generates presigned URL          â”‚             â”‚

  - Better for business logic

â”‚  â”‚  3. Direct upload to S3 from browser            â”‚             â”‚- `500 Internal Server Error`: Server error while saving file

**Trade-offs:**

- Need to maintain two codebasesâ”‚  â”‚  4. S3 event triggers Go Ingestion Service      â”‚             â”‚

- Different deployment pipelines

- Team needs expertise in both languagesâ”‚  â”‚  5. File stored with metadata                   â”‚             â”‚## ğŸ—ï¸ Solution Architecture



### 2. Event-Driven Upload Architectureâ”‚  â”‚                                                  â”‚             â”‚



**Decision:** Use presigned URLs and storage events instead of direct upload to backendâ”‚  â”‚  Structure: /uploads/YYYY/MM/DD/filename.csv    â”‚             â”‚### 2. Health Check



**Rationale:**â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜             â”‚

- **Scalability:** Direct S3 upload bypasses backend bottleneck

- **Performance:** No file data through backend serversâ”‚                                                                   â”‚### High-Level Architecture

- **Bandwidth:** Reduced backend bandwidth costs

- **Security:** Presigned URLs with expiration (5 minutes)â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”            â”‚

- **Decoupling:** Upload and processing are independent

â”‚  â”‚      Relational Database (PostgreSQL)            â”‚            â”‚**Endpoint:** `GET /health`

**Flow:**

1. Frontend requests presigned URL from Python APIâ”‚  â”‚                                                   â”‚            â”‚

2. Frontend uploads directly to S3

3. S3 event triggers Go ingestion serviceâ”‚  â”‚  Tables:                                          â”‚            â”‚```

4. Go service processes asynchronously

â”‚  â”‚  â”œâ”€ pricing_records                              â”‚            â”‚

**Trade-offs:**

- More complex upload flowâ”‚  â”‚  â”‚  â”œâ”€ id (PK)                                   â”‚            â”‚â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”**Example:**

- Requires S3 event configuration

- Need to handle failed uploadsâ”‚  â”‚  â”‚  â”œâ”€ store_id (Indexed)                        â”‚            â”‚



### 3. Streaming CSV Processingâ”‚  â”‚  â”‚  â”œâ”€ sku (Indexed)                             â”‚            â”‚â”‚                         Load Balancer / API Gateway             â”‚```bash



**Decision:** Use streaming parser instead of loading entire file into memoryâ”‚  â”‚  â”‚  â”œâ”€ product_name                              â”‚            â”‚



**Rationale:**â”‚  â”‚  â”‚  â”œâ”€ price                                     â”‚            â”‚â”‚                    (Rate Limiting, Auth, CORS)                  â”‚curl http://localhost:8080/health

- **Memory Efficiency:** Process 10MB+ files with constant memory

- **Performance:** Start processing immediatelyâ”‚  â”‚  â”‚  â”œâ”€ date (Indexed)                            â”‚            â”‚

- **Scalability:** Handle unlimited file sizes

- **Error Recovery:** Stop on first errorâ”‚  â”‚  â”‚  â”œâ”€ created_at                                â”‚            â”‚â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜```



**Implementation:**â”‚  â”‚  â”‚  â””â”€ updated_at                                â”‚            â”‚

```go

// Stream CSV line by lineâ”‚  â”‚  â”‚                                                â”‚            â”‚                             â”‚

reader := csv.NewReader(file)

for {â”‚  â”‚  â”œâ”€ upload_history                               â”‚            â”‚

    record, err := reader.Read()

    if err == io.EOF {â”‚  â”‚  â”‚  â”œâ”€ id (PK)                                   â”‚            â”‚        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”**Response (200 OK):**

        break

    }â”‚  â”‚  â”‚  â”œâ”€ filename                                  â”‚            â”‚

    processBatch(record)

}â”‚  â”‚  â”‚  â”œâ”€ upload_date                               â”‚            â”‚        â”‚                    â”‚                    â”‚```json

```

â”‚  â”‚  â”‚  â”œâ”€ status                                    â”‚            â”‚

### 4. PostgreSQL Over NoSQL

â”‚  â”‚  â”‚  â”œâ”€ records_count                             â”‚            â”‚        â–¼                    â–¼                    â–¼{

**Decision:** Use PostgreSQL as primary database

â”‚  â”‚  â”‚  â””â”€ user_id                                   â”‚            â”‚

**Rationale:**

- **ACID Compliance:** Critical for financial pricing dataâ”‚  â”‚  â”‚                                                â”‚            â”‚â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  "status": "healthy",

- **Complex Queries:** Support for JOINs, aggregations, window functions

- **Data Integrity:** Foreign keys, constraints, triggersâ”‚  â”‚  â””â”€ audit_logs                                   â”‚            â”‚

- **Full-Text Search:** Built-in search capabilities

- **Proven at Scale:** Battle-tested with large datasetsâ”‚  â”‚     â”œâ”€ id (PK)                                   â”‚            â”‚â”‚ Angular SPA  â”‚    â”‚   Go Upload  â”‚    â”‚   Python     â”‚  "timestamp": "2026-02-10T12:00:00Z"



| Feature | PostgreSQL | MongoDB |â”‚  â”‚     â”œâ”€ table_name                                â”‚            â”‚

|---------|-----------|---------|

| ACID | âœ… Strong | âš ï¸ Weak |â”‚  â”‚     â”œâ”€ record_id                                 â”‚            â”‚â”‚   (Static)   â”‚    â”‚   Service    â”‚    â”‚ Data Service â”‚}

| Joins | âœ… Excellent | âŒ Limited |

| Schema | âœ… Enforced | âš ï¸ Flexible |â”‚  â”‚     â”œâ”€ action (INSERT/UPDATE/DELETE)             â”‚            â”‚

| Scale | âœ… Vertical + Horizontal | âœ… Horizontal |

â”‚  â”‚     â”œâ”€ old_value                                 â”‚            â”‚â”‚              â”‚    â”‚              â”‚    â”‚              â”‚```

### 5. Batch Insert for Database Operations

â”‚  â”‚     â”œâ”€ new_value                                 â”‚            â”‚

**Decision:** Batch insert records instead of individual inserts

â”‚  â”‚     â”œâ”€ user_id                                   â”‚            â”‚â”‚ - Angular 17 â”‚    â”‚ - Gin HTTP   â”‚    â”‚ - FastAPI    â”‚

**Rationale:**

- **Performance:** 10-100x faster than single insertsâ”‚  â”‚     â””â”€ timestamp                                 â”‚            â”‚

- **Network:** Reduced round trips to database

- **Transactions:** Single transaction for batchâ”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜            â”‚â”‚ - Material   â”‚    â”‚ - CSV Parse  â”‚    â”‚ - SQLAlchemy â”‚## File Storage

- **Error Handling:** Rollback entire batch on error

â”‚                                                                   â”‚

**Implementation:**

```goâ”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”            â”‚â”‚ - State Mgmt â”‚    â”‚ - Validation â”‚    â”‚ - Pandas     â”‚

// Batch size: 1000 records

const batchSize = 1000â”‚  â”‚           Cache Layer (Redis) - Optional         â”‚            â”‚

for i := 0; i < len(records); i += batchSize {

    batch := records[i:min(i+batchSize, len(records))]â”‚  â”‚                                                   â”‚            â”‚â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜Uploaded files are stored in the `./uploads` directory with a timestamp prefix to ensure uniqueness.

    db.BatchInsert(batch)

}â”‚  â”‚  - Session Storage                                â”‚            â”‚

```

â”‚  â”‚  - Search Results Cache                           â”‚            â”‚                           â”‚                    â”‚

### 6. Optimistic Locking for Concurrent Edits

â”‚  â”‚  - Rate Limiting                                  â”‚            â”‚

**Decision:** Use version column for optimistic locking

â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜            â”‚                           â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜## Testing

**Rationale:**

- **Performance:** No locks, better concurrencyâ””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

- **User Experience:** Users notified only on actual conflicts

- **Scalability:** Works in distributed systems```                                      â”‚



**Implementation:**

```python

# Check version before update### Data Flow Sequence                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”### Create a test CSV file:

UPDATE pricing_records

SET price = $1, version = version + 1

WHERE id = $2 AND version = $3

# If affected rows = 0, conflict detected#### Upload Flow                    â”‚                 â”‚                 â”‚

```

```

### 7. Direct S3 Upload from Frontend

1. User â†’ Angular UI: Select CSV file                    â–¼                 â–¼                 â–¼**PowerShell:**

**Decision:** Upload files directly from browser to S3

2. Angular â†’ Python API: Request presigned URL

**Rationale:**

- **Performance:** No backend involvement in file transfer3. Python API â†’ S3: Generate presigned URL            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”```powershell

- **Scalability:** Backend not bottleneck for uploads

- **Cost:** Reduced bandwidth costs4. Python API â†’ Angular: Return presigned URL

- **User Experience:** Progress bar works directly

5. Angular â†’ S3: Direct upload using presigned URL            â”‚  PostgreSQL  â”‚  â”‚    Redis    â”‚  â”‚  S3 Storage  â”‚@"

**Security:**

- Presigned URLs with 5-minute expiration6. S3 â†’ Event Trigger: File upload complete event

- Limit file size at S3 level

- Restrict to specific content type7. Event Trigger â†’ Go Ingestion Svc: Trigger processing            â”‚   Database   â”‚  â”‚    Cache    â”‚  â”‚  (CSV Files) â”‚name,email,age



---8. Go Ingestion Svc â†’ S3: Download and stream file



## ğŸš€ Non-Functional Requirements9. Go Ingestion Svc: Validate CSV structure            â”‚              â”‚  â”‚             â”‚  â”‚              â”‚John Doe,john@example.com,30



### 1. Performance10. Go Ingestion Svc: Parse CSV (streaming)



**Requirements:**11. Go Ingestion Svc â†’ PostgreSQL: Batch insert records            â”‚ - Pricing    â”‚  â”‚ - Sessions  â”‚  â”‚ - Archive    â”‚Jane Smith,jane@example.com,25

- Response Time: < 2 seconds for search queries

- Upload Speed: Support 10MB files in < 5 seconds12. Go Ingestion Svc â†’ PostgreSQL: Update upload_history

- Concurrent Users: Support 1000+ concurrent users

- Throughput: Process 100+ CSV uploads per minute13. PostgreSQL â†’ Python API: Notify completion            â”‚   Records    â”‚  â”‚ - Search    â”‚  â”‚ - Backup     â”‚"@ | Out-File -FilePath test.csv -Encoding utf8

- Database Queries: < 100ms for indexed lookups

14. Python API â†’ Angular: Push notification (WebSocket)

**Design Approach:**

- Database indexing on store_id, sku, date columns15. Angular: Display success message            â”‚ - Indexes    â”‚  â”‚   Results   â”‚  â”‚              â”‚```

- Redis caching for frequent searches (TTL: 5 minutes)

- Connection pooling (50-100 connections)```

- Asynchronous processing for large files

- CDN for static assets            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜



### 2. Scalability#### Search Flow



**Requirements:**``````### Upload the test file:

- Horizontal Scaling: Stateless microservices

- Data Volume: Handle 100M+ pricing records1. User â†’ Angular UI: Enter search criteria

- Store Growth: Support 3000+ stores, expandable to 10,000+

- Multi-Region: Deploy across multiple geographic regions2. Angular â†’ Python API: POST /api/v1/pricing/search```powershell



**Design Approach:**3. Python API â†’ Redis: Check cache

- Microservices architecture

- Database sharding by region/country4. Redis â†’ Python API: Cache miss### Microservices ArchitectureInvoke-RestMethod -Uri "http://localhost:8080/upload" -Method Post -Form @{file = Get-Item -Path "test.csv"}

- Read replicas for query distribution (3 replicas)

- Auto-scaling based on CPU/memory (50-80% threshold)5. Python API â†’ PostgreSQL: Execute search query

- Message queues for async tasks (RabbitMQ/SQS)

6. PostgreSQL â†’ Python API: Return results```

### 3. Availability & Reliability

7. Python API â†’ Redis: Store in cache

**Requirements:**

- Uptime: 99.9% availability (< 8.76 hours downtime/year)8. Python API â†’ Angular: Return JSON response1. **Frontend Service (Angular)**

- Disaster Recovery: RTO < 4 hours, RPO < 1 hour

- Fault Tolerance: No single point of failure9. Angular: Display results in data grid

- Data Integrity: Zero data loss

```   - Single Page Application## Building for Production

**Design Approach:**

- Multi-AZ deployment (3 availability zones)

- Database replication (primary + 2 replicas)

- Service redundancy (min 3 instances per service)#### Edit Flow   - Responsive UI with Material Design

- Health checks and circuit breakers

- Daily automated backups with 30-day retention```



### 4. Security1. User â†’ Angular UI: Edit pricing record inline   - Client-side validation```bash



**Requirements:**2. Angular â†’ Python API: PUT /api/v1/pricing/{id}

- Authentication: OAuth 2.0 / JWT tokens

- Authorization: Role-based access control (RBAC)3. Python API: Validate changes   - Real-time updatesgo build -o product-service.exe main.go

- Data Encryption: TLS 1.3 in transit, AES-256 at rest

- Audit Logging: All actions logged and immutable4. Python API â†’ PostgreSQL: Begin transaction

- Compliance: GDPR, SOC 2 compliance

5. Python API â†’ PostgreSQL: Update pricing_record```

**Design Approach:**

- API Gateway with authentication6. Python API â†’ PostgreSQL: Insert audit_log

- JWT tokens (1-hour expiration)

- Encrypted database connections7. Python API â†’ PostgreSQL: Commit transaction2. **Upload Service (Go + Gin)**

- Secrets management (AWS Secrets Manager/Vault)

- Input validation and sanitization8. PostgreSQL â†’ Python API: Confirm update

- Parameterized queries (prevent SQL injection)

9. Python API â†’ Redis: Invalidate cache   - High-performance file upload handlingRun the executable:

### 5. Maintainability

10. Python API â†’ Angular: Return updated record

**Requirements:**

- Code Quality: > 80% test coverage11. Angular: Update UI with new values   - CSV validation and parsing```bash

- Documentation: API docs, architecture diagrams

- Monitoring: Real-time metrics and alerts```

- Logging: Centralized structured logging

   - Concurrent processing./product-service.exe

**Design Approach:**

- Comprehensive unit and integration tests---

- OpenAPI/Swagger documentation

- Prometheus metrics + Grafana dashboards   - File storage management```

- ELK stack for log aggregation

- CI/CD pipelines with automated testing## ğŸ› ï¸ Technology Stack



### 6. Usability



**Requirements:**### Frontend

- Responsive Design: Mobile, tablet, desktop support

- Accessibility: WCAG 2.1 Level AA compliance- **Framework:** Angular 17+3. **Data Service (Python + FastAPI)**## Configuration

- Internationalization: Multi-language support

- User Experience: Intuitive interface, < 3 clicks to any feature- **UI Library:** Angular Material / PrimeNG



**Design Approach:**- **State Management:** NgRx / Akita   - RESTful API for CRUD operations

- Angular Material responsive components

- ARIA labels and keyboard navigation- **HTTP Client:** Angular HttpClient

- i18n with Angular's built-in support

- Loading indicators and progress bars- **Form Validation:** Reactive Forms   - Complex search queries- **MAX_UPLOAD_SIZE**: Default is 10MB (can be modified in `main.go`)

- Error messages with actionable guidance

- **File Upload:** ng-file-upload / custom directive

### 7. Data Consistency

   - Data transformation- **UPLOAD_PATH**: Default is `./uploads` (can be modified in `main.go`)

**Requirements:**

- ACID Compliance: Transactional integrity### Backend Services

- Eventual Consistency: For cross-region sync

- Data Validation: Strong type checking   - Business logic processing- **PORT**: Set via environment variable (default: 8080)



**Design Approach:**#### 1. Python API Service (Data Operations)

- PostgreSQL transactions

- Optimistic locking for concurrent edits- **Language:** Python 3.11+

- Data validation at multiple layers (frontend, backend, database)

- Conflict resolution strategies- **Framework:** FastAPI



---- **ORM:** SQLAlchemy---## Project Structure



## ğŸ“ Assumptions- **Data Processing:** Pandas



### Business Assumptions- **Validation:** Pydantic

1. **Store Count:** Starting with 3000 stores, growing to 10,000 in 3 years

2. **Upload Frequency:** Each store uploads pricing data daily- **Authentication:** JWT / OAuth2

3. **File Size:** Average CSV file contains 1,000-10,000 records (< 10MB)

4. **Data Retention:** Pricing history retained for 2 years minimum- **Key Responsibilities:**## ğŸ› ï¸ Technology Stack```

5. **Peak Load:** 20% of stores upload simultaneously during business hours

6. **User Base:** 500 concurrent users (store managers, analysts, admins)  - Generate presigned URLs for S3 uploads

7. **Pricing Changes:** 10% of records updated monthly via edit feature

  - Search and filter pricing records.

### Technical Assumptions

1. **Network:** Minimum 1 Mbps upload speed at store locations  - CRUD operations on pricing data

2. **Browser Support:** Modern browsers (Chrome, Firefox, Safari, Edge - last 2 versions)

3. **Database Size:** Initial ~50GB, growing to 500GB in 3 years  - User authentication and authorization### Frontendâ”œâ”€â”€ main.go           # Main application file with HTTP handlers

4. **API Calls:** Average 1000 API requests per minute during peak hours

5. **Search Queries:** 70% use 1-2 criteria, 30% use 3+ criteria  - Real-time notifications (WebSocket)

6. **Edit Operations:** 80% single record edits, 20% bulk updates

7. **Infrastructure:** Cloud-hosted (AWS/Azure/GCP)- **Framework:** Angular 17+â”œâ”€â”€ go.mod            # Go module definition



### Data Assumptions#### 2. Go Ingestion Service (File Processing)

1. **CSV Format:** Consistent column order: `Store ID, SKU, Product Name, Price, Date`

2. **Store ID:** Alphanumeric, max 20 characters- **Language:** Go 1.25+- **UI Library:** Angular Material / PrimeNGâ”œâ”€â”€ go.sum            # Go module checksums

3. **SKU:** Alphanumeric, max 50 characters

4. **Product Name:** UTF-8 string, max 200 characters- **Framework:** Gin Web Framework

5. **Price:** Decimal with 2 decimal places, positive values, range: 0.01 - 999,999.99

6. **Date:** ISO 8601 format (YYYY-MM-DD)- **CSV Processing:** encoding/csv (streaming)- **State Management:** NgRx / Akitaâ”œâ”€â”€ README.md         # This file

7. **Character Encoding:** UTF-8

8. **Delimiter:** Comma (,)- **Concurrency:** Goroutines for parallel processing

9. **Header Row:** First row contains column names

10. **No Empty Fields:** All fields are required- **Validation:** Custom validators- **HTTP Client:** Angular HttpClientâ”œâ”€â”€ .gitignore        # Git ignore file



### Security Assumptions- **Key Responsibilities:**

1. **Authentication:** Corporate SSO integration (SAML/OAuth 2.0)

2. **Authorization:** Three roles:  - Listen to S3 storage events- **Form Validation:** Reactive Formsâ””â”€â”€ uploads/          # Directory for uploaded files (created automatically)

   - **Store Manager:** Upload files, view own store data

   - **Analyst:** Search, view, edit all data  - Validate CSV file structure

   - **Admin:** All permissions + user management

3. **Network:** Application accessible via corporate VPN or whitelisted IPs  - Stream and parse large CSV files```

4. **Compliance:** PCI DSS for pricing data, GDPR for EU stores

  - Batch insert records into database

### Operational Assumptions

1. **Monitoring:** 24/7 monitoring with on-call support  - Error handling and retry logic### Backend Services

2. **Backup:** Daily automated backups at 2 AM (off-peak)

3. **Backup Retention:** 30 days online, 2 years archived

4. **Updates:** Monthly maintenance windows (4 hours max, Saturday 2-6 AM)

5. **Support:** Email and ticket-based support (24-hour response time)### Data Layer#### Upload Service (Go)

6. **SLA:** 99.9% uptime

- **Primary Database:** PostgreSQL 15+- **Language:** Go 1.25+

---

  - ACID compliance for pricing data- **Framework:** Gin Web Framework

## ğŸš€ Getting Started

  - Full-text search capabilities- **CSV Processing:** encoding/csv

### Prerequisites

  - Partitioning for large datasets- **File Handling:** io, os packages

- **Go** 1.25+

- **Python** 3.11+  - Replication for high availability- **Validation:** Custom middleware

- **PostgreSQL** 15+

- **Redis** 7+ (optional)

- **Docker** and Docker Compose (recommended)

- **Cache:** Redis 7+ (Optional)#### Data Service (Python)

### Quick Start with Docker Compose

  - Session storage- **Language:** Python 3.11+

```powershell

# Clone repository  - Search results caching- **Framework:** FastAPI / Flask

git clone https://github.com/yourusername/retail-pricing-system.git

cd retail-pricing-system  - Rate limiting- **ORM:** SQLAlchemy



# Start all services- **Data Processing:** Pandas

docker-compose up -d

- **Object Storage:** AWS S3 / Azure Blob / Local FileSystem- **Validation:** Pydantic

# View logs

docker-compose logs -f  - CSV file storage



# Stop services  - File archival### Data Layer

docker-compose down

```  - Event notifications- **Primary Database:** PostgreSQL 15+



**Services available at:**- **Cache:** Redis 7+

- Frontend: http://localhost:4200

- Python API: http://localhost:8000### DevOps & Infrastructure- **Object Storage:** AWS S3 / Azure Blob Storage

- Go Ingestion: http://localhost:8080

- PostgreSQL: localhost:5432- **Containerization:** Docker- **Message Queue:** RabbitMQ / AWS SQS (for async processing)

- Redis: localhost:6379

- **Orchestration:** Kubernetes / Docker Compose

### Manual Setup - Go Ingestion Service

- **CI/CD:** GitHub Actions / GitLab CI### DevOps & Infrastructure

```powershell

# Clone this repository- **Monitoring:** Prometheus + Grafana- **Containerization:** Docker

git clone https://github.com/yourusername/golang-project-product-service.git

cd golang-project-product-service- **Logging:** ELK Stack (Elasticsearch, Logstash, Kibana)- **Orchestration:** Kubernetes



# Install dependencies- **API Gateway:** Kong / Nginx (Optional)- **CI/CD:** GitHub Actions / GitLab CI

go mod download

- **Monitoring:** Prometheus + Grafana

# Configure environment

cp .env.example .env---- **Logging:** ELK Stack (Elasticsearch, Logstash, Kibana)

notepad .env

- **API Gateway:** Kong / AWS API Gateway

# Run the service

go run cmd/server/main.go## âœ… Functional Requirements

```

---

**Service runs on:** http://localhost:8080

### 1. CSV Upload and Persistence

### Environment Variables

- âœ… Upload CSV files containing pricing data## âœ… Functional Requirements

```env

# Server- âœ… CSV Structure: `Store ID, SKU, Product Name, Price, Date`

PORT=8080

GIN_MODE=release- âœ… File validation (format, size, structure)### 1. CSV Upload and Persistence



# File Upload- âœ… Automatic parsing and data extraction- âœ… Upload CSV files containing pricing data

MAX_UPLOAD_SIZE=10485760

UPLOAD_PATH=./uploads- âœ… Persistent storage in database- âœ… CSV Structure: `Store ID, SKU, Product Name, Price, Date`



# Database- âœ… File archival in object storage- âœ… File validation (format, size, structure)

DATABASE_URL=postgresql://user:pass@localhost:5432/pricing_db

DB_MAX_CONNECTIONS=50- âœ… Upload history and audit trail- âœ… Automatic parsing and data extraction



# S3 (Optional)- âœ… Support for large files (streaming processing)- âœ… Persistent storage in database

USE_S3=false

AWS_REGION=us-east-1- âœ… Duplicate detection and handling- âœ… File archival in object storage

S3_BUCKET=retail-pricing-uploads

- âœ… Error reporting with line numbers- âœ… Upload history and audit trail

# Security

JWT_SECRET=your-secret-key



# Logging**Implementation:**### 2. Search and Filter Capabilities

LOG_LEVEL=info

- Frontend: Angular file upload with drag-and-drop- âœ… Search by Store ID

# Processing

BATCH_SIZE=1000- Backend: Go service for efficient CSV processing- âœ… Search by SKU

```

- Storage: S3 for files, PostgreSQL for records- âœ… Search by Product Name (partial match)

### Testing the Service

- âœ… Filter by Price range

#### Health Check

```powershell### 2. Search and Filter Capabilities- âœ… Filter by Date range

Invoke-RestMethod -Uri "http://localhost:8080/health" -Method Get

```- âœ… Search by Store ID (exact match)- âœ… Combined search criteria



#### Create Test CSV- âœ… Search by SKU (exact match)- âœ… Pagination and sorting

```powershell

@"- âœ… Search by Product Name (partial match, case-insensitive)- âœ… Export search results

Store ID,SKU,Product Name,Price,Date

ST001,SKU12345,Laptop Computer,999.99,2026-02-17- âœ… Filter by Price range (min/max)

ST001,SKU12346,Wireless Mouse,29.99,2026-02-17

ST002,SKU12347,USB Keyboard,49.99,2026-02-17- âœ… Filter by Date range (start/end)### 3. Edit and Update Records

"@ | Out-File -FilePath pricing_test.csv -Encoding utf8

```- âœ… Combined search criteria (AND logic)- âœ… Inline editing in data grid



#### Upload CSV- âœ… Pagination (configurable page size)- âœ… Bulk update capabilities

```powershell

$response = Invoke-WebRequest -Uri "http://localhost:8080/upload" `- âœ… Sorting (ascending/descending)- âœ… Data validation on updates

    -Method Post `

    -Form @{file = Get-Item -Path "pricing_test.csv"}- âœ… Export search results to CSV- âœ… Change tracking and versioning



$response.Content | ConvertFrom-Json | ConvertTo-Json- âœ… Save search filters as presets- âœ… Rollback functionality

```

- âœ… Audit log of all changes

**Expected Response:**

```json**Implementation:**

{

  "message": "File uploaded successfully",- Frontend: Advanced search form with reactive forms---

  "filename": "1708171234_pricing_test.csv",

  "size": 256,- Backend: Python FastAPI with SQLAlchemy queries

  "rows": 4,

  "columns": 5- Database: Indexed columns for fast lookups## ğŸš€ Non-Functional Requirements

}

```- Cache: Redis for frequently searched queries



---### 1. Performance



## ğŸ“¦ Source Implementation### 3. Edit and Update Records- **Response Time:** < 2 seconds for search queries



### Repository Structure- âœ… Inline editing in data grid- **Upload Speed:** Support 10MB files in < 5 seconds



```- âœ… Single record updates- **Concurrent Users:** Support 1000+ concurrent users

golang-project-product-service/        # THIS REPOSITORY

â”‚- âœ… Bulk update capabilities- **Throughput:** Process 100+ CSV uploads per minute

â”œâ”€â”€ cmd/

â”‚   â””â”€â”€ server/- âœ… Data validation on updates (type, range, format)- **Database Queries:** < 100ms for indexed lookups

â”‚       â””â”€â”€ main.go                    # Application entry point

â”‚- âœ… Change tracking and versioning

â”œâ”€â”€ internal/

â”‚   â”œâ”€â”€ handlers/- âœ… Audit log of all changes (who, what, when)**Design Approach:**

â”‚   â”‚   â”œâ”€â”€ upload.go                  # File upload handler

â”‚   â”‚   â”œâ”€â”€ health.go                  # Health check- âœ… Rollback functionality- Database indexing on Store ID, SKU, and Date

â”‚   â”‚   â””â”€â”€ event.go                   # S3 event handler

â”‚   â”œâ”€â”€ middleware/- âœ… Optimistic locking for concurrent edits- Redis caching for frequent searches

â”‚   â”‚   â”œâ”€â”€ auth.go                    # Authentication

â”‚   â”‚   â”œâ”€â”€ cors.go                    # CORS- âœ… Confirmation dialog for destructive operations- Connection pooling

â”‚   â”‚   â””â”€â”€ logging.go                 # Request logging

â”‚   â”œâ”€â”€ models/- Asynchronous processing for large files

â”‚   â”‚   â”œâ”€â”€ pricing.go                 # Pricing record model

â”‚   â”‚   â””â”€â”€ response.go                # API responses**Implementation:**- CDN for static assets

â”‚   â”œâ”€â”€ services/

â”‚   â”‚   â”œâ”€â”€ validator.go               # CSV validation- Frontend: Editable data grid with Material Table

â”‚   â”‚   â”œâ”€â”€ parser.go                  # CSV parsing (streaming)

â”‚   â”‚   â”œâ”€â”€ storage.go                 # File storage (S3/local)- Backend: Python FastAPI with transaction support### 2. Scalability

â”‚   â”‚   â””â”€â”€ database.go                # Database operations

â”‚   â””â”€â”€ config/- Database: Audit logs table with triggers- **Horizontal Scaling:** Stateless microservices

â”‚       â””â”€â”€ config.go                  # Configuration

â”‚- Validation: Server-side validation with Pydantic- **Data Volume:** Handle 100M+ pricing records

â”œâ”€â”€ pkg/

â”‚   â””â”€â”€ utils/- **Store Growth:** Support 3000+ stores, expandable to 10,000+

â”‚       â”œâ”€â”€ csv.go                     # CSV utilities

â”‚       â””â”€â”€ s3.go                      # S3 utilities---- **Multi-Region:** Deploy across multiple geographic regions

â”‚

â”œâ”€â”€ uploads/                           # Temporary storage

â”‚

â”œâ”€â”€ tests/## ğŸš€ Non-Functional Requirements**Design Approach:**

â”‚   â”œâ”€â”€ integration/

â”‚   â””â”€â”€ unit/- Microservices architecture

â”‚

â”œâ”€â”€ go.mod                             # Go module### 1. Performance- Database sharding by region/country

â”œâ”€â”€ go.sum                             # Dependencies

â”œâ”€â”€ Dockerfile                         # Container image**Requirements:**- Read replicas for query distribution

â”œâ”€â”€ .env.example                       # Environment template

â””â”€â”€ README.md                          # This file- Response Time: < 2 seconds for search queries- Auto-scaling based on load

```

- Upload Speed: Support 10MB files in < 5 seconds- Message queues for async tasks

### Related Repositories

- Concurrent Users: Support 1000+ concurrent users

- **Frontend:** [Angular Web Application](https://github.com/yourusername/frontend)

- **Python API Service:** [FastAPI Data Service](https://github.com/yourusername/data-service)- Throughput: Process 100+ CSV uploads per minute### 3. Availability & Reliability

- **Infrastructure:** [Kubernetes & Terraform](https://github.com/yourusername/infrastructure)

- **Database:** [Schema & Migrations](https://github.com/yourusername/database)- Database Queries: < 100ms for indexed lookups- **Uptime:** 99.9% availability (< 8.76 hours downtime/year)



### API Endpoints- **Disaster Recovery:** RTO < 4 hours, RPO < 1 hour



#### Go Ingestion Service (Port 8080)**Design Approach:**- **Fault Tolerance:** No single point of failure



**POST /upload**- **Database Optimization:**- **Data Integrity:** Zero data loss

- Upload CSV file with pricing data

- Max file size: 10MB  - B-tree indexes on store_id, sku, date columns

- Format: multipart/form-data

- Returns: Upload metadata (filename, size, rows, columns)  - Composite indexes for common query patterns**Design Approach:**



**GET /health**  - Query optimization with EXPLAIN ANALYZE- Multi-AZ deployment

- Health check endpoint

- Returns: Service status and timestamp  - Connection pooling (50-100 connections)- Database replication (primary-replica)



#### Python Data Service (Port 8000)  - Regular automated backups



**POST /api/v1/upload/presigned-url**- **Caching Strategy:**- Health checks and circuit breakers

- Generate presigned URL for S3 upload

  - Redis for search results (TTL: 5 minutes)- Retry mechanisms with exponential backoff

**GET /api/v1/pricing**

- Search pricing records with filters  - Browser caching for static assets



**PUT /api/v1/pricing/{id}**  - API response caching with ETag### 4. Security

- Update pricing record

  - **Authentication:** OAuth 2.0 / JWT tokens

**DELETE /api/v1/pricing/{id}**

- Delete pricing record- **Concurrent Processing:**- **Authorization:** Role-based access control (RBAC)



**Full API documentation:** http://localhost:8000/docs  - Go goroutines for parallel CSV processing- **Data Encryption:** TLS 1.3 in transit, AES-256 at rest



---  - Batch inserts (1000 records per batch)- **Audit Logging:** All actions logged and immutable



## ğŸ“Š Deployment  - Async processing for large files- **Compliance:** GDPR, SOC 2 compliance



### Docker Build  



```powershell- **CDN:****Design Approach:**

# Build image

docker build -t go-ingestion-service:latest .  - CloudFront/CloudFlare for static assets- API Gateway with authentication



# Run container  - Geographic distribution- Encrypted database connections

docker run -d -p 8080:8080 --name go-ingestion go-ingestion-service:latest

```- Secrets management (Vault/AWS Secrets Manager)



### Kubernetes Deployment### 2. Scalability- Input validation and sanitization



```powershell**Requirements:**- Regular security audits

# Deploy to Kubernetes

kubectl apply -f k8s/deployment.yaml- Horizontal Scaling: Stateless microservices

kubectl apply -f k8s/service.yaml

- Data Volume: Handle 100M+ pricing records### 5. Maintainability

# Scale deployment

kubectl scale deployment go-ingestion --replicas=3- Store Growth: Support 3000+ stores, expandable to 10,000+- **Code Quality:** > 80% test coverage



# Auto-scaling- Multi-Region: Deploy across multiple geographic regions- **Documentation:** API docs, architecture diagrams

kubectl autoscale deployment go-ingestion --cpu-percent=70 --min=2 --max=10

```- Storage: Accommodate 10TB+ of CSV files- **Monitoring:** Real-time metrics and alerts



---- **Logging:** Centralized structured logging



## ğŸ§ª Testing**Design Approach:**



```powershell- **Microservices:****Design Approach:**

# Run all tests

go test ./... -v  - Independent scaling of upload and API services- Comprehensive unit and integration tests



# Run with coverage  - Load balancing with round-robin- OpenAPI/Swagger documentation

go test ./... -v -cover -coverprofile=coverage.out

  - Auto-scaling based on CPU/memory (50-80% threshold)- Prometheus metrics + Grafana dashboards

# View coverage report

go tool cover -html=coverage.out  - ELK stack for log aggregation

```

- **Database Scaling:**- CI/CD pipelines

---

  - Table partitioning by date (monthly partitions)

## ğŸ“„ License

  - Read replicas for query distribution (3 replicas)### 6. Usability

This project is licensed under the MIT License.

  - Database sharding by region/country- **Responsive Design:** Mobile, tablet, desktop support

---

  - **Accessibility:** WCAG 2.1 Level AA compliance

## ğŸ“§ Contact

- **Object Storage:**- **Internationalization:** Multi-language support

**Repository:** https://github.com/yourusername/golang-project-product-service

  - S3 with lifecycle policies- **User Experience:** Intuitive interface, < 3 clicks to any feature

**Project:** Retail Pricing Management System

  - Automatic archival to Glacier after 90 days

**Last Updated:** February 17, 2026

  - Multi-region replication**Design Approach:**

  - Angular Material responsive components

- **Message Queues:**- ARIA labels and keyboard navigation

  - RabbitMQ/SQS for async processing- i18n with Angular's built-in support

  - Dead letter queues for failed uploads- User testing and feedback loops



### 3. Availability & Reliability### 7. Data Consistency

**Requirements:**- **ACID Compliance:** Transactional integrity

- Uptime: 99.9% availability (< 8.76 hours downtime/year)- **Eventual Consistency:** For cross-region sync

- Disaster Recovery: RTO < 4 hours, RPO < 1 hour- **Data Validation:** Strong type checking

- Fault Tolerance: No single point of failure

- Data Integrity: Zero data loss**Design Approach:**

- PostgreSQL transactions

**Design Approach:**- Optimistic locking for concurrent edits

- **High Availability:**- Data validation at multiple layers

  - Multi-AZ deployment (3 availability zones)- Conflict resolution strategies

  - Database replication (primary + 2 replicas)

  - Service redundancy (min 3 instances per service)---

  

- **Health Checks:**## ğŸ¨ Design Decisions

  - Liveness probes (every 10 seconds)

  - Readiness probes before routing traffic### 1. Microservices Architecture

  - Circuit breakers for external dependencies**Decision:** Split responsibilities into specialized services (Upload, Data)

  

- **Backup & Recovery:****Rationale:**

  - Daily automated database backups- **Separation of Concerns:** Upload service focuses on file handling; data service handles business logic

  - Point-in-time recovery (PITR) enabled- **Technology Optimization:** Go excels at concurrent I/O (file uploads); Python excels at data manipulation

  - S3 versioning for file recovery- **Independent Scaling:** Scale upload service during peak upload times, scale data service during high query load

  - Backup retention: 30 days- **Fault Isolation:** Failure in one service doesn't affect others

  - **Team Autonomy:** Different teams can own different services

- **Monitoring & Alerts:**

  - Real-time monitoring with Prometheus### 2. Go for Upload Service

  - Alert on error rate > 5%**Decision:** Use Go with Gin framework for file upload service

  - Alert on response time > 3s

  - 24/7 on-call rotation**Rationale:**

- **Performance:** Go's goroutines handle concurrent uploads efficiently

### 4. Security- **Low Memory Footprint:** Critical for processing large files

**Requirements:**- **Fast Compilation:** Quick iteration during development

- Authentication: OAuth 2.0 / JWT tokens- **Built-in Concurrency:** Native support for parallel CSV parsing

- Authorization: Role-based access control (RBAC)- **Static Binary:** Easy deployment without dependencies

- Data Encryption: TLS 1.3 in transit, AES-256 at rest

- Audit Logging: All actions logged and immutable### 3. Python for Data Service

- Compliance: GDPR, SOC 2 compliance**Decision:** Use Python with FastAPI/Flask for data operations



**Design Approach:****Rationale:**

- **Authentication & Authorization:**- **Data Processing:** Pandas library for complex data transformations

  - JWT tokens with 1-hour expiration- **ORM Maturity:** SQLAlchemy for robust database interactions

  - Refresh tokens with 7-day expiration- **Rich Ecosystem:** Libraries for validation, serialization, testing

  - Role-based permissions (Store Manager, Analyst, Admin)- **Rapid Development:** Quick implementation of business logic

  - API key authentication for service-to-service- **Team Expertise:** Wider talent pool familiar with Python

  

- **Encryption:**### 4. PostgreSQL as Primary Database

  - TLS 1.3 for all API communication**Decision:** Use PostgreSQL over MongoDB or MySQL

  - Database encryption at rest (AES-256)

  - S3 server-side encryption (SSE-S3)**Rationale:**

  - Secrets management with AWS Secrets Manager- **ACID Compliance:** Critical for financial pricing data

  - **Complex Queries:** Support for JOINs, aggregations, window functions

- **Input Validation:**- **JSON Support:** Flexibility for schema evolution

  - Server-side validation for all inputs- **Full-Text Search:** Built-in search capabilities

  - Parameterized queries (prevent SQL injection)- **Proven at Scale:** Battle-tested with large datasets

  - File type validation (CSV only)- **Open Source:** No licensing costs

  - File size limits (10MB max)

  - CSV content sanitization### 5. Redis for Caching

  **Decision:** Implement Redis for caching layer

- **Audit & Compliance:**

  - Immutable audit logs**Rationale:**

  - Log retention: 2 years- **Speed:** In-memory storage for sub-millisecond response times

  - GDPR right to erasure implementation- **Common Queries:** Cache frequent searches (e.g., by Store ID)

  - Data anonymization for non-production environments- **Session Storage:** User sessions and temporary data

- **Rate Limiting:** API throttling implementation

### 5. Maintainability- **Reduced Database Load:** Offload read operations

**Requirements:**

- Code Quality: > 80% test coverage### 6. S3 for File Storage

- Documentation: API docs, architecture diagrams**Decision:** Store uploaded CSV files in object storage

- Monitoring: Real-time metrics and alerts

- Logging: Centralized structured logging**Rationale:**

- **Durability:** 99.999999999% durability (11 nines)

**Design Approach:**- **Scalability:** Unlimited storage capacity

- **Testing:**- **Cost-Effective:** Pay-per-use, cheaper than database storage

  - Unit tests (80% coverage)- **Audit Trail:** Keep original files for compliance

  - Integration tests for critical paths- **Lifecycle Policies:** Automatic archival and deletion

  - End-to-end tests for user workflows

  - Load testing with k6/JMeter### 7. Single Page Application (Angular)

  **Decision:** Build SPA instead of server-rendered pages

- **Documentation:**

  - OpenAPI/Swagger for APIs**Rationale:**

  - Architecture Decision Records (ADR)- **User Experience:** Instant navigation, no page reloads

  - README for each service- **Responsive:** Better mobile and tablet experience

  - Inline code comments- **API-First:** Clean separation between frontend and backend

  - **Offline Capability:** Service workers for offline functionality

- **Observability:**- **Rich Interactions:** Real-time updates, drag-drop uploads

  - Structured JSON logging

  - Correlation IDs for request tracing### 8. API Gateway Pattern

  - Distributed tracing with Jaeger**Decision:** Use API Gateway as single entry point

  - Application Performance Monitoring (APM)

  **Rationale:**

- **CI/CD:**- **Centralized Auth:** Single authentication point

  - Automated testing on every commit- **Rate Limiting:** Protect backend services from abuse

  - Automated deployment to staging- **Request Routing:** Dynamic routing to services

  - Blue-green deployment for production- **CORS Handling:** Centralized CORS configuration

  - Rollback capabilities- **Monitoring:** Single point for metrics and logging



### 6. Usability### 9. Event-Driven for Large Files

**Requirements:****Decision:** Use message queues for processing large CSV files

- Responsive Design: Mobile, tablet, desktop support

- Accessibility: WCAG 2.1 Level AA compliance**Rationale:**

- Internationalization: Multi-language support- **Async Processing:** Don't block user while processing

- User Experience: Intuitive interface, < 3 clicks to any feature- **Retry Logic:** Automatic retry on failures

- **Load Leveling:** Prevent system overload

**Design Approach:**- **Auditability:** Track processing status

- **UI/UX:**- **Scalability:** Add workers as needed

  - Material Design principles

  - Consistent color scheme and typography### 10. Multi-Region Deployment

  - Loading indicators for async operations**Decision:** Deploy across multiple geographic regions

  - Error messages with actionable guidance

  - Keyboard shortcuts for power users**Rationale:**

  - **Latency:** Reduce latency for global users

- **Accessibility:**- **Compliance:** Data residency requirements (GDPR)

  - ARIA labels for screen readers- **Disaster Recovery:** Geographic redundancy

  - Keyboard navigation support- **Load Distribution:** Distribute traffic globally

  - High contrast mode

  - Font size adjustment---

  

- **Internationalization:**## ğŸ“ Assumptions

  - Angular i18n support

  - Separate language files (en, es, fr, de)### Business Assumptions

  - Date/time localization1. **Store Count:** Starting with 3000 stores, growing to 10,000 in 3 years

  - Currency formatting2. **Upload Frequency:** Each store uploads pricing data daily

  3. **File Size:** Average CSV file contains 1,000-10,000 records (< 10MB)

- **Performance:**4. **Data Retention:** Pricing history retained for 2 years minimum

  - Lazy loading for large datasets5. **Peak Load:** 20% of stores upload simultaneously during business hours

  - Virtual scrolling for data grids6. **User Base:** 500 concurrent users (store managers, analysts, admins)

  - Debounced search inputs7. **Pricing Changes:** 10% of records updated monthly via edit feature

  - Progressive web app (PWA) capabilities

### Technical Assumptions

### 7. Data Consistency1. **Network:** Minimum 1 Mbps upload speed at store locations

**Requirements:**2. **Browser Support:** Modern browsers (Chrome, Firefox, Safari, Edge - last 2 versions)

- ACID Compliance: Transactional integrity3. **Database Size:** Initial database size ~50GB, growing to 500GB in 3 years

- Eventual Consistency: For cross-region sync4. **API Calls:** Average 1000 API requests per minute during peak hours

- Data Validation: Strong type checking5. **Search Queries:** 70% of searches use 1-2 criteria, 30% use 3+ criteria

6. **Edit Operations:** 80% single record edits, 20% bulk updates

**Design Approach:**7. **Infrastructure:** Cloud-hosted (AWS/Azure/GCP), not on-premises

- **Database Transactions:**

  - Use PostgreSQL transactions for updates### Data Assumptions

  - Isolation level: READ COMMITTED1. **CSV Format:** Consistent column order: Store ID, SKU, Product Name, Price, Date

  - Optimistic locking with version column2. **Store ID:** Alphanumeric, max 20 characters, unique per country

  3. **SKU:** Alphanumeric, max 50 characters, unique per product

- **Data Validation:**4. **Product Name:** UTF-8 string, max 200 characters

  - Schema validation at API level (Pydantic)5. **Price:** Decimal with 2 decimal places, positive values only

  - Database constraints (NOT NULL, CHECK, FK)6. **Date:** ISO 8601 format (YYYY-MM-DD)

  - Application-level validation7. **Character Encoding:** UTF-8 for international character support

  

- **Conflict Resolution:**### Security Assumptions

  - Last-write-wins for concurrent edits1. **Authentication:** Corporate SSO integration (SAML/OAuth)

  - User notification on conflicts2. **Authorization:** Three roles: Store Manager (upload only), Analyst (search/edit), Admin (all)

  - Merge strategies for bulk updates3. **Network:** Application accessible only via corporate VPN or whitelisted IPs

4. **Compliance:** Subject to PCI DSS for pricing data, GDPR for EU stores

---

### Operational Assumptions

## ğŸ¨ Design Decisions1. **Monitoring:** 24/7 monitoring with on-call support

2. **Backup:** Daily automated backups with 30-day retention

### 1. Microservices Architecture with Language Optimization3. **Updates:** Monthly maintenance windows for updates (4 hours max)

**Decision:** Use Go for ingestion and Python for API operations4. **Support:** Email and ticket-based support (no phone support initially)



**Rationale:**---

- **Go for File Processing:**

  - Superior performance for I/O operations## ğŸ“ Project Structure

  - Efficient memory management for large files

  - Native goroutines for concurrent processing```

  - Fast CSV parsing with streamingretail-pricing-system/

  - Single binary deploymentâ”‚

  â”œâ”€â”€ frontend/                          # Angular Frontend

- **Python for Data Operations:**â”‚   â”œâ”€â”€ src/

  - Rich ecosystem for data manipulation (Pandas)â”‚   â”‚   â”œâ”€â”€ app/

  - FastAPI for rapid API developmentâ”‚   â”‚   â”‚   â”œâ”€â”€ components/

  - SQLAlchemy for complex queriesâ”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ upload/           # File upload component

  - Easy integration with data science toolsâ”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ search/           # Search interface

  - Better for business logicâ”‚   â”‚   â”‚   â”‚   â””â”€â”€ data-grid/        # Editable data grid

â”‚   â”‚   â”‚   â”œâ”€â”€ services/

**Trade-offs:**â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ upload.service.ts

- Need to maintain two codebasesâ”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ pricing.service.ts

- Different deployment pipelinesâ”‚   â”‚   â”‚   â”‚   â””â”€â”€ auth.service.ts

- Team needs expertise in both languagesâ”‚   â”‚   â”‚   â”œâ”€â”€ models/

â”‚   â”‚   â”‚   â””â”€â”€ guards/

### 2. Event-Driven Upload Architectureâ”‚   â”‚   â”œâ”€â”€ assets/

**Decision:** Use presigned URLs and storage events instead of direct upload to backendâ”‚   â”‚   â””â”€â”€ environments/

â”‚   â”œâ”€â”€ angular.json

**Rationale:**â”‚   â”œâ”€â”€ package.json

- **Scalability:** Direct S3 upload bypasses backend bottleneckâ”‚   â””â”€â”€ README.md

- **Performance:** No file data through backend serversâ”‚

- **Bandwidth:** Reduced backend bandwidth costsâ”œâ”€â”€ upload-service/                    # Go Upload Microservice (THIS REPO)

- **Security:** Presigned URLs with expiration (5 minutes)â”‚   â”œâ”€â”€ cmd/

- **Decoupling:** Upload and processing are independentâ”‚   â”‚   â””â”€â”€ server/

â”‚   â”‚       â””â”€â”€ main.go               # Entry point

**Flow:**â”‚   â”œâ”€â”€ internal/

1. Frontend requests presigned URL from Python APIâ”‚   â”‚   â”œâ”€â”€ handlers/                 # HTTP handlers

2. Frontend uploads directly to S3â”‚   â”‚   â”œâ”€â”€ middleware/               # Custom middleware

3. S3 event triggers Go ingestion serviceâ”‚   â”‚   â”œâ”€â”€ models/                   # Data models

4. Go service processes asynchronouslyâ”‚   â”‚   â”œâ”€â”€ services/                 # Business logic

â”‚   â”‚   â””â”€â”€ config/                   # Configuration

**Trade-offs:**â”‚   â”œâ”€â”€ pkg/                          # Shared packages

- More complex upload flowâ”‚   â”œâ”€â”€ uploads/                      # Temporary upload storage

- Requires S3 event configurationâ”‚   â”œâ”€â”€ go.mod

- Need to handle failed uploadsâ”‚   â”œâ”€â”€ go.sum

â”‚   â”œâ”€â”€ Dockerfile

### 3. Streaming CSV Processingâ”‚   â””â”€â”€ README.md

**Decision:** Use streaming parser instead of loading entire file into memoryâ”‚

â”œâ”€â”€ data-service/                      # Python Data Microservice

**Rationale:**â”‚   â”œâ”€â”€ app/

- **Memory Efficiency:** Process 10MB+ files with constant memoryâ”‚   â”‚   â”œâ”€â”€ main.py                   # FastAPI entry point

- **Performance:** Start processing immediatelyâ”‚   â”‚   â”œâ”€â”€ routers/

- **Scalability:** Handle unlimited file sizesâ”‚   â”‚   â”‚   â”œâ”€â”€ pricing.py            # CRUD endpoints

- **Error Recovery:** Stop on first error, don't process entire fileâ”‚   â”‚   â”‚   â”œâ”€â”€ search.py             # Search endpoints

â”‚   â”‚   â”‚   â””â”€â”€ health.py

**Implementation:**â”‚   â”‚   â”œâ”€â”€ models/

```goâ”‚   â”‚   â”‚   â”œâ”€â”€ pricing.py            # SQLAlchemy models

// Stream CSV line by lineâ”‚   â”‚   â”‚   â””â”€â”€ schemas.py            # Pydantic schemas

reader := csv.NewReader(file)â”‚   â”‚   â”œâ”€â”€ services/

for {â”‚   â”‚   â”œâ”€â”€ database/

    record, err := reader.Read()â”‚   â”‚   â”œâ”€â”€ middleware/

    if err == io.EOF {â”‚   â”‚   â””â”€â”€ config/

        breakâ”‚   â”œâ”€â”€ tests/

    }â”‚   â”œâ”€â”€ requirements.txt

    // Process record immediatelyâ”‚   â”œâ”€â”€ Dockerfile

    processBatch(record)â”‚   â””â”€â”€ README.md

}â”‚

```â”œâ”€â”€ infrastructure/                    # Infrastructure as Code

â”‚   â”œâ”€â”€ kubernetes/

### 4. PostgreSQL Over NoSQLâ”‚   â”œâ”€â”€ terraform/

**Decision:** Use PostgreSQL as primary databaseâ”‚   â””â”€â”€ docker-compose.yml

â”‚

**Rationale:**â”œâ”€â”€ database/

- **ACID Compliance:** Critical for financial pricing dataâ”‚   â”œâ”€â”€ migrations/

- **Complex Queries:** Support for JOINs, aggregations, window functionsâ”‚   â”œâ”€â”€ seeds/

- **Data Integrity:** Foreign keys, constraints, triggersâ”‚   â””â”€â”€ schema.sql

- **Full-Text Search:** Built-in search capabilitiesâ”‚

- **Proven at Scale:** Battle-tested with large datasetsâ””â”€â”€ docs/

- **Cost:** Open source, no licensing fees    â”œâ”€â”€ architecture/

    â”œâ”€â”€ api/

**Comparison:**    â””â”€â”€ deployment/

| Feature | PostgreSQL | MongoDB |```

|---------|-----------|---------|

| ACID | âœ… Strong | âš ï¸ Weak |---

| Joins | âœ… Excellent | âŒ Limited |

| Schema | âœ… Enforced | âš ï¸ Flexible |## ğŸš€ Getting Started

| Scale | âœ… Vertical + Horizontal | âœ… Horizontal |

| Query Language | SQL | MongoDB Query |### Upload Service (Go + Gin) - This Repository



### 5. Redis for Caching (Optional)#### Prerequisites

**Decision:** Implement caching layer with Redis- **Go** 1.25+

- **PostgreSQL** 15+ (optional for local dev)

**Rationale:**- **Redis** 7+ (optional for caching)

- **Performance:** 100x faster than database for common queries

- **Reduced Load:** Offload read operations from PostgreSQL#### Installation

- **Session Storage:** Store user sessions in memory

- **Rate Limiting:** Implement API throttling1. **Clone the repository**

```powershell

**Caching Strategy:**git clone https://github.com/yourusername/golang-project-product-service.git

- Cache search results (TTL: 5 minutes)cd golang-project-product-service

- Cache user sessions (TTL: 1 hour)```

- Invalidate cache on data updates

- Use cache-aside pattern2. **Install dependencies**

```powershell

### 6. Batch Insert for Database Operationsgo mod download

**Decision:** Batch insert records instead of individual inserts```



**Rationale:**3. **Configure environment variables** (optional)

- **Performance:** 10-100x faster than single inserts```powershell

- **Network:** Reduced round trips to database# Create .env file

- **Transactions:** Single transaction for batch@"

- **Error Handling:** Rollback entire batch on errorPORT=8080

MAX_UPLOAD_SIZE=10485760

**Implementation:**UPLOAD_PATH=./uploads

```goLOG_LEVEL=info

// Batch size: 1000 records"@ | Out-File -FilePath .env -Encoding utf8

const batchSize = 1000```

for i := 0; i < len(records); i += batchSize {

    batch := records[i:min(i+batchSize, len(records))]4. **Run the service**

    db.BatchInsert(batch)```powershell

}go run cmd/server/main.go

``````



### 7. Audit Logging with Database TriggersThe service will start on http://localhost:8080

**Decision:** Use database triggers for audit logging

#### Testing the Upload Endpoint

**Rationale:**

- **Consistency:** Can't bypass audit logging**Create a test CSV file:**

- **Performance:** Happens at database level```powershell

- **Completeness:** Captures all changes@"

- **Immutable:** Logs stored separatelyStore ID,SKU,Product Name,Price,Date

ST001,SKU12345,Laptop Computer,999.99,2026-02-17

**Trigger Example:**ST001,SKU12346,Wireless Mouse,29.99,2026-02-17

```sqlST002,SKU12347,USB Keyboard,49.99,2026-02-17

CREATE TRIGGER audit_pricing_update"@ | Out-File -FilePath pricing_test.csv -Encoding utf8

AFTER UPDATE ON pricing_records```

FOR EACH ROW

INSERT INTO audit_logs (table_name, record_id, action, old_value, new_value, user_id, timestamp)**Upload using PowerShell:**

VALUES ('pricing_records', NEW.id, 'UPDATE', row_to_json(OLD), row_to_json(NEW), current_user, NOW());```powershell

```$headers = @{

    "Accept" = "application/json"

### 8. Optimistic Locking for Concurrent Edits}

**Decision:** Use version column for optimistic locking$response = Invoke-WebRequest -Uri "http://localhost:8080/upload" `

    -Method Post `

**Rationale:**    -Headers $headers `

- **Performance:** No locks, better concurrency    -Form @{file = Get-Item -Path "pricing_test.csv"}

- **User Experience:** Users notified only on actual conflicts

- **Scalability:** Works in distributed systems$response.Content | ConvertFrom-Json | ConvertTo-Json

```

**Implementation:**

```python**Expected Response:**

# Check version before update```json

UPDATE pricing_records{

SET price = $1, version = version + 1  "message": "File uploaded successfully",

WHERE id = $2 AND version = $3  "filename": "1739151234_pricing_test.csv",

# If affected rows = 0, conflict detected  "size": 256,

```  "rows": 4,

  "columns": 5

### 9. Direct S3 Upload from Frontend}

**Decision:** Upload files directly from browser to S3```



**Rationale:**#### Health Check

- **Performance:** No backend involvement in file transfer```powershell

- **Scalability:** Backend not bottleneck for uploadsInvoke-RestMethod -Uri "http://localhost:8080/health" -Method Get

- **Cost:** Reduced bandwidth costs```

- **User Experience:** Progress bar works directly

---

**Security:**

- Presigned URLs with 5-minute expiration## ğŸ“š API Documentation

- Limit file size at S3 level

- Restrict to specific content type### Upload Service Endpoints



### 10. Separation of Concerns (SoC)#### POST /upload

**Decision:** Separate file upload, processing, and data operationsUpload a CSV file with pricing data.



**Rationale:****Request:**

- **Maintainability:** Each service has single responsibility- **Method:** POST

- **Scalability:** Scale services independently- **Content-Type:** multipart/form-data

- **Fault Isolation:** Failure in one doesn't affect others- **Parameters:**

- **Team Organization:** Different teams own different services  - `file` (required): CSV file containing pricing data



**Service Boundaries:****CSV Format:**

- **Frontend:** User interface, validation, display```csv

- **Python API:** Data operations, search, authenticationStore ID,SKU,Product Name,Price,Date

- **Go Ingestion:** File processing, validation, database insertST001,SKU12345,Laptop Computer,999.99,2026-02-17

- **PostgreSQL:** Data persistence, queries```

- **S3:** File storage

**Success Response (200 OK):**

---```json

{

## ğŸ“ Assumptions  "message": "File uploaded successfully",

  "filename": "1739151234_pricing.csv",

### Business Assumptions  "size": 524288,

1. **Store Count:** Starting with 3000 stores, growing to 10,000 in 3 years  "rows": 5000,

2. **Upload Frequency:** Each store uploads pricing data daily (once per day)  "columns": 5

3. **File Size:** Average CSV file contains 1,000-10,000 records (< 10MB)}

4. **Data Retention:** Pricing history retained for 2 years minimum```

5. **Peak Load:** 20% of stores upload simultaneously during business hours (8-10 AM)

6. **User Base:** 500 concurrent users (store managers, analysts, admins)**Error Responses:**

7. **Pricing Changes:** 10% of records updated monthly via edit feature- **400 Bad Request:**

8. **Growth Rate:** 15% annual growth in stores and data volume  ```json

  {

### Technical Assumptions    "error": "File too large. Maximum size is 10MB"

1. **Network:** Minimum 1 Mbps upload speed at store locations  }

2. **Browser Support:** Modern browsers (Chrome, Firefox, Safari, Edge - last 2 versions)  ```

3. **Database Size:** Initial database size ~50GB, growing to 500GB in 3 years  ```json

4. **API Calls:** Average 1000 API requests per minute during peak hours  {

5. **Search Queries:** 70% of searches use 1-2 criteria, 30% use 3+ criteria    "error": "Only CSV files are allowed"

6. **Edit Operations:** 80% single record edits, 20% bulk updates  }

7. **Infrastructure:** Cloud-hosted (AWS/Azure/GCP), not on-premises  ```

8. **Internet Connectivity:** 99.5% uptime at store locations  ```json

  {

### Data Assumptions    "error": "Invalid CSV file format"

1. **CSV Format:** Consistent column order: `Store ID, SKU, Product Name, Price, Date`  }

2. **Store ID:** Alphanumeric, max 20 characters, unique per country  ```

3. **SKU:** Alphanumeric, max 50 characters, unique per product

4. **Product Name:** UTF-8 string, max 200 characters, may contain special characters- **500 Internal Server Error:**

5. **Price:** Decimal with 2 decimal places, positive values only, range: 0.01 - 999,999.99  ```json

6. **Date:** ISO 8601 format (YYYY-MM-DD), range: 2020-01-01 to current date  {

7. **Character Encoding:** UTF-8 for international character support    "error": "Error saving file"

8. **Delimiter:** Comma (,) as CSV delimiter  }

9. **Header Row:** First row contains column names  ```

10. **No Empty Fields:** All fields are required

#### GET /health

### Security AssumptionsHealth check endpoint.

1. **Authentication:** Corporate SSO integration (SAML/OAuth 2.0)

2. **Authorization:** Three roles:**Response (200 OK):**

   - Store Manager: Upload files, view own store data```json

   - Analyst: Search, view, edit all data{

   - Admin: All permissions + user management  "status": "healthy",

3. **Network:** Application accessible only via:  "timestamp": "2026-02-17T10:30:00Z"

   - Corporate VPN}

   - Whitelisted IP ranges```

   - Authenticated users only

4. **Compliance:** Subject to:---

   - PCI DSS for pricing data

   - GDPR for EU stores## ğŸš¢ Deployment

   - SOC 2 Type II

### Docker Deployment

### Operational Assumptions

1. **Monitoring:** 24/7 monitoring with on-call support**Build Docker image:**

2. **Backup:** Daily automated backups at 2 AM (off-peak hours)```powershell

3. **Backup Retention:** 30 days online, 2 years archiveddocker build -t upload-service:latest .

4. **Updates:** Monthly maintenance windows for updates (4 hours max, Saturday 2-6 AM)```

5. **Support:** 

   - Email support (24-hour response time)**Run container:**

   - Ticket-based support system```powershell

   - No phone support initiallydocker run -d `

6. **SLA:** 99.9% uptime (8.76 hours downtime per year allowed)  -p 8080:8080 `

7. **Disaster Recovery Testing:** Quarterly DR drills  -e PORT=8080 `

  -e MAX_UPLOAD_SIZE=10485760 `

### Integration Assumptions  --name upload-service `

1. **SSO:** Integration with existing identity provider (Okta/Azure AD)  upload-service:latest

2. **Monitoring:** Integration with existing monitoring tools (Datadog/New Relic)```

3. **Logging:** Logs shipped to central logging system (Splunk/ELK)

4. **Notifications:** Email notifications via SMTP server### Kubernetes Deployment

5. **No POS Integration:** Initially standalone system, future integration possible

**Create deployment:**

---```yaml

apiVersion: apps/v1

## ğŸ“ Project Structurekind: Deployment

metadata:

### Multi-Repository Structure (Recommended)  name: upload-service

spec:

```  replicas: 3

retail-pricing-system/  selector:

â”‚    matchLabels:

â”œâ”€â”€ frontend/                          # Angular Frontend Repository      app: upload-service

â”‚   â”œâ”€â”€ src/  template:

â”‚   â”‚   â”œâ”€â”€ app/    metadata:

â”‚   â”‚   â”‚   â”œâ”€â”€ components/      labels:

â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ upload/           # File upload component        app: upload-service

â”‚   â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ upload.component.ts    spec:

â”‚   â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ upload.component.html      containers:

â”‚   â”‚   â”‚   â”‚   â”‚   â””â”€â”€ upload.component.scss      - name: upload-service

â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ search/           # Search interface        image: upload-service:latest

â”‚   â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ search.component.ts        ports:

â”‚   â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ search.component.html        - containerPort: 8080

â”‚   â”‚   â”‚   â”‚   â”‚   â””â”€â”€ search.component.scss        env:

â”‚   â”‚   â”‚   â”‚   â””â”€â”€ data-grid/        # Editable data grid        - name: PORT

â”‚   â”‚   â”‚   â”‚       â”œâ”€â”€ data-grid.component.ts          value: "8080"

â”‚   â”‚   â”‚   â”‚       â”œâ”€â”€ data-grid.component.html        - name: MAX_UPLOAD_SIZE

â”‚   â”‚   â”‚   â”‚       â””â”€â”€ data-grid.component.scss          value: "10485760"

â”‚   â”‚   â”‚   â”œâ”€â”€ services/```

â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ upload.service.ts

â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ pricing.service.ts**Deploy:**

â”‚   â”‚   â”‚   â”‚   â””â”€â”€ auth.service.ts```powershell

â”‚   â”‚   â”‚   â”œâ”€â”€ models/kubectl apply -f k8s/deployment.yaml

â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ pricing-record.model.tskubectl apply -f k8s/service.yaml

â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ search-criteria.model.ts```

â”‚   â”‚   â”‚   â”‚   â””â”€â”€ user.model.ts

â”‚   â”‚   â”‚   â”œâ”€â”€ guards/---

â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ auth.guard.ts

â”‚   â”‚   â”‚   â”‚   â””â”€â”€ role.guard.ts## ğŸ§ª Testing

â”‚   â”‚   â”‚   â””â”€â”€ interceptors/

â”‚   â”‚   â”‚       â”œâ”€â”€ auth.interceptor.ts### Unit Tests

â”‚   â”‚   â”‚       â””â”€â”€ error.interceptor.ts```powershell

â”‚   â”‚   â”œâ”€â”€ assets/go test ./... -v -cover

â”‚   â”‚   â””â”€â”€ environments/```

â”‚   â”œâ”€â”€ angular.json

â”‚   â”œâ”€â”€ package.json### Integration Tests

â”‚   â”œâ”€â”€ tsconfig.json```powershell

â”‚   â””â”€â”€ README.mdgo test ./... -tags=integration -v

â”‚```

â”œâ”€â”€ golang-project-product-service/    # Go Ingestion Service (THIS REPO)

â”‚   â”œâ”€â”€ cmd/### Load Testing

â”‚   â”‚   â””â”€â”€ server/```powershell

â”‚   â”‚       â””â”€â”€ main.go               # Entry point# Using Apache Bench

â”‚   â”œâ”€â”€ internal/ab -n 1000 -c 10 -T "multipart/form-data" -p pricing_test.csv http://localhost:8080/upload

â”‚   â”‚   â”œâ”€â”€ handlers/                 # HTTP handlers```

â”‚   â”‚   â”‚   â”œâ”€â”€ upload.go

â”‚   â”‚   â”‚   â”œâ”€â”€ health.go---

â”‚   â”‚   â”‚   â””â”€â”€ event.go              # S3 event handler

â”‚   â”‚   â”œâ”€â”€ middleware/               # Custom middleware## ğŸ“Š Monitoring

â”‚   â”‚   â”‚   â”œâ”€â”€ auth.go

â”‚   â”‚   â”‚   â”œâ”€â”€ cors.go### Metrics Exposed

â”‚   â”‚   â”‚   â””â”€â”€ logging.go- Total uploads count

â”‚   â”‚   â”œâ”€â”€ models/                   # Data models- Upload success/failure rate

â”‚   â”‚   â”‚   â”œâ”€â”€ pricing.go- Upload duration histogram

â”‚   â”‚   â”‚   â””â”€â”€ upload_history.go- File size histogram

â”‚   â”‚   â”œâ”€â”€ services/                 # Business logic- Active connections

â”‚   â”‚   â”‚   â”œâ”€â”€ validator.go

â”‚   â”‚   â”‚   â”œâ”€â”€ parser.go### Health Checks

â”‚   â”‚   â”‚   â”œâ”€â”€ storage.go- `/health` endpoint for liveness probe

â”‚   â”‚   â”‚   â””â”€â”€ database.go- Database connectivity check (if implemented)

â”‚   â”‚   â””â”€â”€ config/                   # Configuration

â”‚   â”‚       â””â”€â”€ config.go---

â”‚   â”œâ”€â”€ pkg/                          # Shared packages

â”‚   â”‚   â””â”€â”€ utils/## ğŸ”’ Security Features

â”‚   â”‚       â”œâ”€â”€ csv.go

â”‚   â”‚       â””â”€â”€ s3.go- File size validation (max 10MB)

â”‚   â”œâ”€â”€ uploads/                      # Temporary upload storage- File type validation (CSV only)

â”‚   â”œâ”€â”€ tests/- CSV structure validation

â”‚   â”‚   â”œâ”€â”€ integration/- Input sanitization

â”‚   â”‚   â””â”€â”€ unit/- Error handling without sensitive info disclosure

â”‚   â”œâ”€â”€ go.mod

â”‚   â”œâ”€â”€ go.sum---

â”‚   â”œâ”€â”€ Dockerfile

â”‚   â”œâ”€â”€ .env.example## ğŸ¤ Contributing

â”‚   â””â”€â”€ README.md

â”‚1. Fork the repository

â”œâ”€â”€ data-service/                      # Python Data Microservice2. Create a feature branch (`git checkout -b feature/amazing-feature`)

â”‚   â”œâ”€â”€ app/3. Commit your changes (`git commit -m 'Add amazing feature'`)

â”‚   â”‚   â”œâ”€â”€ main.py                   # FastAPI entry point4. Push to the branch (`git push origin feature/amazing-feature`)

â”‚   â”‚   â”œâ”€â”€ routers/5. Open a Pull Request

â”‚   â”‚   â”‚   â”œâ”€â”€ __init__.py

â”‚   â”‚   â”‚   â”œâ”€â”€ pricing.py            # CRUD endpoints---

â”‚   â”‚   â”‚   â”œâ”€â”€ search.py             # Search endpoints

â”‚   â”‚   â”‚   â”œâ”€â”€ upload.py             # Presigned URL generation## ğŸ“„ License

â”‚   â”‚   â”‚   â”œâ”€â”€ auth.py               # Authentication

â”‚   â”‚   â”‚   â””â”€â”€ health.py             # Health checkThis project is licensed under the MIT License - see the LICENSE file for details.

â”‚   â”‚   â”œâ”€â”€ models/

â”‚   â”‚   â”‚   â”œâ”€â”€ __init__.py---

â”‚   â”‚   â”‚   â”œâ”€â”€ pricing.py            # SQLAlchemy models

â”‚   â”‚   â”‚   â””â”€â”€ upload_history.py## ğŸ“§ Contact & Support

â”‚   â”‚   â”œâ”€â”€ schemas/

â”‚   â”‚   â”‚   â”œâ”€â”€ __init__.py**Project Link:** https://github.com/yourusername/golang-project-product-service

â”‚   â”‚   â”‚   â”œâ”€â”€ pricing.py            # Pydantic schemas

â”‚   â”‚   â”‚   â”œâ”€â”€ search.py**Related Services:**

â”‚   â”‚   â”‚   â””â”€â”€ user.py- Frontend: [Angular Frontend Repository]

â”‚   â”‚   â”œâ”€â”€ services/- Data Service: [Python Data Service Repository]

â”‚   â”‚   â”‚   â”œâ”€â”€ __init__.py

â”‚   â”‚   â”‚   â”œâ”€â”€ pricing_service.py---

â”‚   â”‚   â”‚   â”œâ”€â”€ search_service.py

â”‚   â”‚   â”‚   â”œâ”€â”€ upload_service.py**Last Updated:** February 17, 2026

â”‚   â”‚   â”‚   â””â”€â”€ cache_service.py
â”‚   â”‚   â”œâ”€â”€ database/
â”‚   â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”‚   â”œâ”€â”€ connection.py
â”‚   â”‚   â”‚   â””â”€â”€ session.py
â”‚   â”‚   â”œâ”€â”€ middleware/
â”‚   â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”‚   â”œâ”€â”€ auth.py
â”‚   â”‚   â”‚   â””â”€â”€ error_handler.py
â”‚   â”‚   â””â”€â”€ config/
â”‚   â”‚       â”œâ”€â”€ __init__.py
â”‚   â”‚       â””â”€â”€ settings.py
â”‚   â”œâ”€â”€ migrations/                   # Alembic migrations
â”‚   â”‚   â””â”€â”€ versions/
â”‚   â”œâ”€â”€ tests/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ test_pricing.py
â”‚   â”‚   â””â”€â”€ test_search.py
â”‚   â”œâ”€â”€ requirements.txt
â”‚   â”œâ”€â”€ requirements-dev.txt
â”‚   â”œâ”€â”€ Dockerfile
â”‚   â”œâ”€â”€ .env.example
â”‚   â””â”€â”€ README.md
â”‚
â”œâ”€â”€ infrastructure/                    # Infrastructure as Code
â”‚   â”œâ”€â”€ kubernetes/
â”‚   â”‚   â”œâ”€â”€ deployments/
â”‚   â”‚   â”‚   â”œâ”€â”€ frontend.yaml
â”‚   â”‚   â”‚   â”œâ”€â”€ go-ingestion.yaml
â”‚   â”‚   â”‚   â””â”€â”€ python-api.yaml
â”‚   â”‚   â”œâ”€â”€ services/
â”‚   â”‚   â”‚   â”œâ”€â”€ frontend-service.yaml
â”‚   â”‚   â”‚   â”œâ”€â”€ go-service.yaml
â”‚   â”‚   â”‚   â””â”€â”€ python-service.yaml
â”‚   â”‚   â”œâ”€â”€ ingress/
â”‚   â”‚   â”‚   â””â”€â”€ ingress.yaml
â”‚   â”‚   â”œâ”€â”€ configmaps/
â”‚   â”‚   â”‚   â””â”€â”€ app-config.yaml
â”‚   â”‚   â””â”€â”€ secrets/
â”‚   â”‚       â””â”€â”€ app-secrets.yaml
â”‚   â”œâ”€â”€ terraform/
â”‚   â”‚   â”œâ”€â”€ modules/
â”‚   â”‚   â”‚   â”œâ”€â”€ eks/
â”‚   â”‚   â”‚   â”œâ”€â”€ rds/
â”‚   â”‚   â”‚   â”œâ”€â”€ s3/
â”‚   â”‚   â”‚   â””â”€â”€ vpc/
â”‚   â”‚   â”œâ”€â”€ environments/
â”‚   â”‚   â”‚   â”œâ”€â”€ dev/
â”‚   â”‚   â”‚   â”œâ”€â”€ staging/
â”‚   â”‚   â”‚   â””â”€â”€ prod/
â”‚   â”‚   â””â”€â”€ main.tf
â”‚   â””â”€â”€ docker-compose.yml            # Local development
â”‚
â”œâ”€â”€ database/
â”‚   â”œâ”€â”€ migrations/                   # Database migrations
â”‚   â”‚   â”œâ”€â”€ 001_initial_schema.sql
â”‚   â”‚   â”œâ”€â”€ 002_add_audit_logs.sql
â”‚   â”‚   â””â”€â”€ 003_add_indexes.sql
â”‚   â”œâ”€â”€ seeds/                        # Test data
â”‚   â”‚   â””â”€â”€ sample_data.sql
â”‚   â””â”€â”€ schema.sql                    # Complete schema
â”‚
â”œâ”€â”€ docs/
â”‚   â”œâ”€â”€ architecture/
â”‚   â”‚   â”œâ”€â”€ context-diagram.md
â”‚   â”‚   â”œâ”€â”€ solution-architecture.md
â”‚   â”‚   â”œâ”€â”€ component-diagram.md
â”‚   â”‚   â””â”€â”€ adr/                      # Architecture Decision Records
â”‚   â”‚       â”œâ”€â”€ 001-microservices.md
â”‚   â”‚       â”œâ”€â”€ 002-go-for-ingestion.md
â”‚   â”‚       â””â”€â”€ 003-event-driven-upload.md
â”‚   â”œâ”€â”€ api/
â”‚   â”‚   â”œâ”€â”€ upload-service-api.md
â”‚   â”‚   â””â”€â”€ data-service-api.md
â”‚   â”œâ”€â”€ deployment/
â”‚   â”‚   â””â”€â”€ deployment-guide.md
â”‚   â””â”€â”€ user-guides/
â”‚       â”œâ”€â”€ upload-guide.md
â”‚       â”œâ”€â”€ search-guide.md
â”‚       â””â”€â”€ edit-guide.md
â”‚
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ setup-dev.sh
â”‚   â”œâ”€â”€ run-tests.sh
â”‚   â”œâ”€â”€ deploy.sh
â”‚   â””â”€â”€ seed-database.sh
â”‚
â”œâ”€â”€ .github/
â”‚   â””â”€â”€ workflows/
â”‚       â”œâ”€â”€ ci-go-service.yml
â”‚       â”œâ”€â”€ ci-python-service.yml
â”‚       â”œâ”€â”€ ci-frontend.yml
â”‚       â””â”€â”€ deploy-prod.yml
â”‚
â”œâ”€â”€ docker-compose.yml                # Full stack local development
â”œâ”€â”€ .gitignore
â”œâ”€â”€ LICENSE
â””â”€â”€ README.md                         # Main project README
```

### Current Repository (Go Ingestion Service)

```
golang-project-product-service/
â”‚
â”œâ”€â”€ cmd/
â”‚   â””â”€â”€ server/
â”‚       â””â”€â”€ main.go                   # Application entry point
â”‚
â”œâ”€â”€ internal/
â”‚   â”œâ”€â”€ handlers/
â”‚   â”‚   â”œâ”€â”€ upload.go                 # File upload handler
â”‚   â”‚   â”œâ”€â”€ health.go                 # Health check handler
â”‚   â”‚   â””â”€â”€ event.go                  # S3 event handler (future)
â”‚   â”œâ”€â”€ middleware/
â”‚   â”‚   â”œâ”€â”€ auth.go                   # Authentication middleware
â”‚   â”‚   â”œâ”€â”€ cors.go                   # CORS middleware
â”‚   â”‚   â””â”€â”€ logging.go                # Request logging
â”‚   â”œâ”€â”€ models/
â”‚   â”‚   â”œâ”€â”€ pricing.go                # Pricing record model
â”‚   â”‚   â””â”€â”€ response.go               # API response models
â”‚   â”œâ”€â”€ services/
â”‚   â”‚   â”œâ”€â”€ validator.go              # CSV validation
â”‚   â”‚   â”œâ”€â”€ parser.go                 # CSV parsing (streaming)
â”‚   â”‚   â”œâ”€â”€ storage.go                # File storage (S3/local)
â”‚   â”‚   â””â”€â”€ database.go               # Database operations
â”‚   â””â”€â”€ config/
â”‚       â””â”€â”€ config.go                 # Configuration management
â”‚
â”œâ”€â”€ pkg/
â”‚   â””â”€â”€ utils/
â”‚       â”œâ”€â”€ csv.go                    # CSV utilities
â”‚       â””â”€â”€ s3.go                     # S3 utilities
â”‚
â”œâ”€â”€ uploads/                          # Temporary file storage
â”‚
â”œâ”€â”€ tests/
â”‚   â”œâ”€â”€ integration/
â”‚   â”‚   â””â”€â”€ upload_test.go
â”‚   â””â”€â”€ unit/
â”‚       â”œâ”€â”€ validator_test.go
â”‚       â””â”€â”€ parser_test.go
â”‚
â”œâ”€â”€ go.mod                            # Go module definition
â”œâ”€â”€ go.sum                            # Dependency checksums
â”œâ”€â”€ Dockerfile                        # Container image
â”œâ”€â”€ .env.example                      # Environment variables template
â”œâ”€â”€ .gitignore
â””â”€â”€ README.md                         # This file
```

---

## ğŸš€ Getting Started

### Prerequisites

- **Go** 1.25+
- **Node.js** 18+ and npm (for frontend)
- **Python** 3.11+ (for data service)
- **PostgreSQL** 15+
- **Redis** 7+ (optional, for caching)
- **Docker** and Docker Compose (recommended for local development)
- **AWS CLI** (if using S3)

### Local Development Setup

#### Option 1: Docker Compose (Recommended)

This starts all services with a single command:

```powershell
# Clone the main repository
git clone https://github.com/yourusername/retail-pricing-system.git
cd retail-pricing-system

# Start all services
docker-compose up -d

# View logs
docker-compose logs -f

# Stop all services
docker-compose down
```

**Services will be available at:**
- Frontend: http://localhost:4200
- Python API: http://localhost:8000
- Go Ingestion: http://localhost:8080
- PostgreSQL: localhost:5432
- Redis: localhost:6379

#### Option 2: Manual Setup (Individual Services)

##### 1. Go Ingestion Service (This Repository)

```powershell
# Clone repository
git clone https://github.com/yourusername/golang-project-product-service.git
cd golang-project-product-service

# Install dependencies
go mod download

# Copy environment variables
cp .env.example .env

# Edit .env with your configuration
notepad .env

# Run the service
go run cmd/server/main.go
```

**Service runs on:** http://localhost:8080

##### 2. Database Setup (PostgreSQL)

```powershell
# Using Docker
docker run -d `
  --name pricing-postgres `
  -e POSTGRES_DB=pricing_db `
  -e POSTGRES_USER=pricing_user `
  -e POSTGRES_PASSWORD=your_password `
  -p 5432:5432 `
  postgres:15

# Run migrations
psql -h localhost -U pricing_user -d pricing_db -f database/schema.sql
```

##### 3. Python Data Service

```powershell
# Clone repository
git clone https://github.com/yourusername/data-service.git
cd data-service

# Create virtual environment
python -m venv venv
.\venv\Scripts\Activate.ps1

# Install dependencies
pip install -r requirements.txt

# Copy environment variables
cp .env.example .env

# Run migrations
alembic upgrade head

# Start service
uvicorn app.main:app --reload --port 8000
```

**Service runs on:** http://localhost:8000

##### 4. Angular Frontend

```powershell
# Clone repository
git clone https://github.com/yourusername/frontend.git
cd frontend

# Install dependencies
npm install

# Update environment configuration
notepad src/environments/environment.ts

# Start development server
ng serve
```

**Application runs on:** http://localhost:4200

### Testing the Go Ingestion Service

#### 1. Health Check

```powershell
Invoke-RestMethod -Uri "http://localhost:8080/health" -Method Get
```

**Expected Response:**
```json
{
  "status": "healthy",
  "timestamp": "2026-02-17T10:30:00Z"
}
```

#### 2. Create Test CSV File

```powershell
@"
Store ID,SKU,Product Name,Price,Date
ST001,SKU12345,Laptop Computer,999.99,2026-02-17
ST001,SKU12346,Wireless Mouse,29.99,2026-02-17
ST002,SKU12347,USB Keyboard,49.99,2026-02-17
ST002,SKU12348,Monitor 24 inch,299.99,2026-02-17
ST003,SKU12349,USB Cable,9.99,2026-02-17
"@ | Out-File -FilePath pricing_test.csv -Encoding utf8
```

#### 3. Upload CSV File

```powershell
$response = Invoke-WebRequest -Uri "http://localhost:8080/upload" `
    -Method Post `
    -Form @{file = Get-Item -Path "pricing_test.csv"}

$response.Content | ConvertFrom-Json | ConvertTo-Json -Depth 10
```

**Expected Response:**
```json
{
  "message": "File uploaded successfully",
  "filename": "1708171234_pricing_test.csv",
  "size": 256,
  "rows": 6,
  "columns": 5
}
```

#### 4. Verify Upload

```powershell
# Check uploaded file
Get-ChildItem .\uploads\
```

### Environment Variables

#### Go Ingestion Service (.env)

```env
# Server Configuration
PORT=8080
GIN_MODE=release

# File Upload
MAX_UPLOAD_SIZE=10485760
UPLOAD_PATH=./uploads

# Database
DATABASE_URL=postgresql://pricing_user:your_password@localhost:5432/pricing_db
DB_MAX_CONNECTIONS=50
DB_MAX_IDLE_CONNECTIONS=10

# S3 Configuration (Optional)
USE_S3=false
AWS_REGION=us-east-1
S3_BUCKET=retail-pricing-uploads
AWS_ACCESS_KEY_ID=your_access_key
AWS_SECRET_ACCESS_KEY=your_secret_key

# Redis (Optional)
REDIS_URL=redis://localhost:6379/0

# Security
JWT_SECRET=your-secret-key-change-in-production

# Logging
LOG_LEVEL=info
LOG_FORMAT=json

# Processing
BATCH_SIZE=1000
MAX_GOROUTINES=10
```

#### Python Data Service (.env)

```env
# Server Configuration
PORT=8000
WORKERS=4

# Database
DATABASE_URL=postgresql://pricing_user:your_password@localhost:5432/pricing_db

# Redis
REDIS_URL=redis://localhost:6379/0
CACHE_TTL=300

# Security
SECRET_KEY=your-secret-key-change-in-production
JWT_ALGORITHM=HS256
ACCESS_TOKEN_EXPIRE_MINUTES=60

# CORS
CORS_ORIGINS=http://localhost:4200,https://yourdomain.com

# S3
AWS_REGION=us-east-1
S3_BUCKET=retail-pricing-uploads
PRESIGNED_URL_EXPIRATION=300

# Logging
LOG_LEVEL=info
```

---

## ğŸ“š API Documentation

### Go Ingestion Service (Port 8080)

#### POST /upload
Upload a CSV file with pricing data.

**Request:**
```http
POST /upload HTTP/1.1
Host: localhost:8080
Content-Type: multipart/form-data

file: <binary-csv-file>
```

**CSV Format Requirements:**
- **Header Row:** `Store ID,SKU,Product Name,Price,Date`
- **Delimiter:** Comma (,)
- **Encoding:** UTF-8
- **Max Size:** 10MB
- **File Extension:** .csv

**Example CSV:**
```csv
Store ID,SKU,Product Name,Price,Date
ST001,SKU12345,Laptop Computer,999.99,2026-02-17
ST002,SKU12346,Wireless Mouse,29.99,2026-02-17
```

**Success Response (200 OK):**
```json
{
  "message": "File uploaded successfully",
  "filename": "1708171234_pricing.csv",
  "size": 524288,
  "rows": 5000,
  "columns": 5
}
```

**Error Responses:**

**400 Bad Request - File too large:**
```json
{
  "error": "File too large. Maximum size is 10MB"
}
```

**400 Bad Request - Invalid file type:**
```json
{
  "error": "Only CSV files are allowed"
}
```

**400 Bad Request - Invalid CSV format:**
```json
{
  "error": "Invalid CSV file format"
}
```

**400 Bad Request - Empty file:**
```json
{
  "error": "CSV file is empty"
}
```

**500 Internal Server Error:**
```json
{
  "error": "Error saving file"
}
```

#### GET /health
Health check endpoint for monitoring.

**Request:**
```http
GET /health HTTP/1.1
Host: localhost:8080
```

**Response (200 OK):**
```json
{
  "status": "healthy",
  "timestamp": "2026-02-17T10:30:00Z"
}
```

### Python Data Service (Port 8000)

Full API documentation available at: http://localhost:8000/docs (Swagger UI)

#### POST /api/v1/upload/presigned-url
Generate presigned URL for direct S3 upload.

**Request:**
```json
{
  "filename": "pricing_data.csv",
  "content_type": "text/csv"
}
```

**Response (200 OK):**
```json
{
  "upload_url": "https://s3.amazonaws.com/bucket/...",
  "file_key": "uploads/2026/02/17/1708171234_pricing_data.csv",
  "expires_in": 300
}
```

#### GET /api/v1/pricing
Search and retrieve pricing records.

**Query Parameters:**
- `store_id` (optional): Filter by store ID (exact match)
- `sku` (optional): Filter by SKU (exact match)
- `product_name` (optional): Filter by product name (partial match, case-insensitive)
- `min_price` (optional): Minimum price (inclusive)
- `max_price` (optional): Maximum price (inclusive)
- `start_date` (optional): Start date (YYYY-MM-DD, inclusive)
- `end_date` (optional): End date (YYYY-MM-DD, inclusive)
- `page` (optional): Page number (default: 1)
- `limit` (optional): Records per page (default: 50, max: 1000)
- `sort_by` (optional): Sort field (default: date)
- `sort_order` (optional): asc or desc (default: desc)

**Example Request:**
```http
GET /api/v1/pricing?store_id=ST001&start_date=2026-01-01&page=1&limit=50
```

**Response (200 OK):**
```json
{
  "data": [
    {
      "id": 1,
      "store_id": "ST001",
      "sku": "SKU12345",
      "product_name": "Laptop Computer",
      "price": 999.99,
      "date": "2026-02-17",
      "created_at": "2026-02-17T10:00:00Z",
      "updated_at": "2026-02-17T10:00:00Z",
      "version": 1
    }
  ],
  "pagination": {
    "page": 1,
    "limit": 50,
    "total": 5000,
    "pages": 100
  }
}
```

#### GET /api/v1/pricing/{id}
Get a single pricing record by ID.

**Response (200 OK):**
```json
{
  "id": 1,
  "store_id": "ST001",
  "sku": "SKU12345",
  "product_name": "Laptop Computer",
  "price": 999.99,
  "date": "2026-02-17",
  "created_at": "2026-02-17T10:00:00Z",
  "updated_at": "2026-02-17T10:00:00Z",
  "version": 1
}
```

#### PUT /api/v1/pricing/{id}
Update a pricing record.

**Request:**
```json
{
  "price": 1099.99,
  "product_name": "Laptop Computer - Updated",
  "version": 1
}
```

**Response (200 OK):**
```json
{
  "id": 1,
  "store_id": "ST001",
  "sku": "SKU12345",
  "product_name": "Laptop Computer - Updated",
  "price": 1099.99,
  "date": "2026-02-17",
  "created_at": "2026-02-17T10:00:00Z",
  "updated_at": "2026-02-17T11:00:00Z",
  "version": 2
}
```

**Error (409 Conflict - Concurrent Edit):**
```json
{
  "error": "Concurrent modification detected. Please refresh and try again.",
  "code": "CONCURRENT_MODIFICATION"
}
```

#### DELETE /api/v1/pricing/{id}
Delete a pricing record.

**Response (200 OK):**
```json
{
  "message": "Record deleted successfully"
}
```

#### GET /api/v1/health
Health check endpoint.

**Response (200 OK):**
```json
{
  "status": "healthy",
  "timestamp": "2026-02-17T10:30:00Z",
  "database": "connected",
  "redis": "connected"
}
```

---

## ğŸš¢ Deployment

### Docker Deployment

#### Build Docker Images

```powershell
# Go Ingestion Service
docker build -t go-ingestion-service:latest -f Dockerfile .

# Python Data Service
cd ../data-service
docker build -t python-data-service:latest -f Dockerfile .

# Angular Frontend
cd ../frontend
docker build -t angular-frontend:latest -f Dockerfile .
```

#### Run with Docker Compose

```powershell
# Start all services
docker-compose up -d

# View logs
docker-compose logs -f go-ingestion
docker-compose logs -f python-api
docker-compose logs -f frontend

# Stop services
docker-compose down

# Stop and remove volumes
docker-compose down -v
```

### Kubernetes Deployment

#### Prerequisites
- Kubernetes cluster (EKS, AKS, GKE, or local minikube)
- kubectl configured
- Docker images pushed to container registry

#### Deploy Services

```powershell
# Create namespace
kubectl create namespace retail-pricing

# Deploy PostgreSQL
kubectl apply -f infrastructure/kubernetes/deployments/postgres.yaml

# Deploy Redis
kubectl apply -f infrastructure/kubernetes/deployments/redis.yaml

# Deploy Go Ingestion Service
kubectl apply -f infrastructure/kubernetes/deployments/go-ingestion.yaml

# Deploy Python Data Service
kubectl apply -f infrastructure/kubernetes/deployments/python-api.yaml

# Deploy Frontend
kubectl apply -f infrastructure/kubernetes/deployments/frontend.yaml

# Deploy Ingress
kubectl apply -f infrastructure/kubernetes/ingress/ingress.yaml

# Check deployment status
kubectl get pods -n retail-pricing
kubectl get services -n retail-pricing
```

#### Scale Services

```powershell
# Scale Go Ingestion Service
kubectl scale deployment go-ingestion --replicas=3 -n retail-pricing

# Scale Python API Service
kubectl scale deployment python-api --replicas=5 -n retail-pricing

# Auto-scaling
kubectl autoscale deployment go-ingestion --cpu-percent=70 --min=2 --max=10 -n retail-pricing
```

### Production Deployment Checklist

- [ ] Environment variables configured
- [ ] Database migrations applied
- [ ] Database backups configured
- [ ] SSL/TLS certificates installed
- [ ] Monitoring and alerting set up
- [ ] Logging configured
- [ ] Rate limiting enabled
- [ ] CORS origins configured
- [ ] Authentication/authorization enabled
- [ ] Health checks configured
- [ ] Auto-scaling policies set
- [ ] Disaster recovery plan documented
- [ ] Load testing completed
- [ ] Security audit completed

---

## ğŸ§ª Testing

### Unit Tests

#### Go Service
```powershell
# Run all tests
go test ./... -v

# Run with coverage
go test ./... -v -cover -coverprofile=coverage.out

# View coverage report
go tool cover -html=coverage.out

# Run specific test
go test ./internal/services -v -run TestValidateCSV
```

#### Python Service
```powershell
# Activate virtual environment
.\venv\Scripts\Activate.ps1

# Run all tests
pytest tests/ -v

# Run with coverage
pytest tests/ -v --cov=app --cov-report=html

# Run specific test
pytest tests/test_pricing.py::test_search_pricing -v
```

### Integration Tests

```powershell
# Start test environment
docker-compose -f docker-compose.test.yml up -d

# Run integration tests
go test ./tests/integration -v

# Cleanup
docker-compose -f docker-compose.test.yml down -v
```

### Load Testing

#### Using Apache Bench
```powershell
# Test health endpoint
ab -n 10000 -c 100 http://localhost:8080/health

# Test upload endpoint (requires proper multipart data)
ab -n 1000 -c 10 -T "multipart/form-data" -p test.csv http://localhost:8080/upload
```

#### Using k6
```powershell
# Install k6
choco install k6

# Run load test
k6 run scripts/load-tests/upload-test.js

# Run with custom VUs and duration
k6 run --vus 100 --duration 5m scripts/load-tests/search-test.js
```

### End-to-End Tests

```powershell
# Frontend E2E tests (Cypress)
cd frontend
npm run e2e

# Run headless
npm run e2e:headless
```

---

## ğŸ“Š Monitoring & Observability

### Metrics (Prometheus)

**Key Metrics:**
- `http_requests_total` - Total HTTP requests
- `http_request_duration_seconds` - Request latency
- `http_errors_total` - Error count
- `csv_files_processed_total` - Files processed
- `csv_records_inserted_total` - Records inserted
- `database_connections_active` - Active DB connections
- `cache_hit_rate` - Redis cache hit rate

**Accessing Metrics:**
- Go Service: http://localhost:8080/metrics
- Python Service: http://localhost:8000/metrics

### Dashboards (Grafana)

**Pre-built Dashboards:**
1. System Overview
2. Upload Service Metrics
3. Data Service Metrics
4. Database Performance
5. User Activity

**Access:** http://localhost:3000 (default credentials: admin/admin)

### Logging (ELK Stack)

**Log Levels:**
- DEBUG: Detailed diagnostic information
- INFO: General informational messages
- WARN: Warning messages
- ERROR: Error messages
- FATAL: Critical errors

**Log Format (JSON):**
```json
{
  "timestamp": "2026-02-17T10:30:00Z",
  "level": "INFO",
  "service": "go-ingestion",
  "message": "File uploaded successfully",
  "correlation_id": "abc123",
  "user_id": "user@example.com",
  "filename": "pricing.csv",
  "records": 5000
}
```

### Alerts

**Critical Alerts:**
- Service downtime (> 1 minute)
- Error rate > 5%
- Response time > 3 seconds
- Database connection failures
- Disk space < 10%

**Warning Alerts:**
- CPU usage > 80%
- Memory usage > 85%
- Error rate > 2%
- Response time > 2 seconds

---

## ğŸ”’ Security

### Authentication Flow
1. User logs in via SSO (OAuth 2.0)
2. Backend issues JWT token (1-hour expiration)
3. Frontend stores token in memory
4. Token included in Authorization header for API requests
5. Backend validates token on each request

### Authorization (RBAC)

**Roles:**
- **Store Manager:**
  - Upload files
  - View own store data
  
- **Analyst:**
  - Upload files
  - Search all data
  - Edit all data
  - Export data
  
- **Administrator:**
  - All analyst permissions
  - User management
  - System configuration
  - View audit logs

### Data Protection

**In Transit:**
- TLS 1.3 for all API communication
- Certificate pinning for mobile apps

**At Rest:**
- Database encryption (AES-256)
- S3 server-side encryption (SSE-S3)
- Encrypted backups

**Input Validation:**
- Server-side validation for all inputs
- Parameterized SQL queries
- File type validation
- File size limits
- Content sanitization

---

## ğŸ¤ Contributing

Please read [CONTRIBUTING.md](CONTRIBUTING.md) for details on our code of conduct and the process for submitting pull requests.

### Development Workflow
1. Fork the repository
2. Create a feature branch (`git checkout -b feature/amazing-feature`)
3. Write tests for your changes
4. Make your changes
5. Run tests and linters
6. Commit your changes (`git commit -m 'Add amazing feature'`)
7. Push to the branch (`git push origin feature/amazing-feature`)
8. Open a Pull Request

### Code Standards

**Go:**
- Follow [Effective Go](https://golang.org/doc/effective_go.html)
- Use `gofmt` for formatting
- Run `golangci-lint` for linting
- Minimum 80% test coverage

**Python:**
- Follow PEP 8
- Use `black` for formatting
- Use `flake8` for linting
- Use type hints
- Minimum 80% test coverage

**Angular:**
- Follow [Angular Style Guide](https://angular.io/guide/styleguide)
- Use `prettier` for formatting
- Use `eslint` for linting
- Use TypeScript strict mode

**Commit Messages:**
- Follow [Conventional Commits](https://www.conventionalcommits.org/)
- Format: `type(scope): description`
- Example: `feat(upload): add progress bar for large files`

---

## ğŸ“„ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

---

## ğŸ‘¥ Team & Support

**Project Team:**
- Architecture Lead: [Name]
- Backend Lead (Go): [Name]
- Backend Lead (Python): [Name]
- Frontend Lead (Angular): [Name]
- DevOps Lead: [Name]
- QA Lead: [Name]

**Contact:**
- Email: pricing-system-support@company.com
- Slack: #retail-pricing-system
- Issue Tracker: GitHub Issues

---

## ğŸ—ºï¸ Roadmap

### Phase 1 (Q1 2026) - âœ… Completed
- [x] Basic upload functionality
- [x] Search and filter
- [x] Edit capabilities
- [x] Authentication
- [x] PostgreSQL integration
- [x] Docker deployment

### Phase 2 (Q2 2026) - ğŸš§ In Progress
- [x] S3 integration with presigned URLs
- [x] Event-driven architecture
- [ ] Redis caching
- [ ] Real-time notifications (WebSocket)
- [ ] Bulk operations
- [ ] Advanced analytics dashboard

### Phase 3 (Q3 2026) - ğŸ“‹ Planned
- [ ] Scheduled imports (FTP/SFTP)
- [ ] Price comparison across stores
- [ ] Mobile app (iOS/Android)
- [ ] Multi-language support
- [ ] Advanced reporting
- [ ] Data export (Excel, PDF)

### Phase 4 (Q4 2026) - ğŸ’¡ Future
- [ ] Machine learning price predictions
- [ ] Automated price optimization
- [ ] Competitive price monitoring
- [ ] AI-powered insights
- [ ] Integration with POS systems
- [ ] Real-time price updates

---

## ğŸ“– Additional Resources

### Documentation
- [Architecture Decision Records (ADR)](docs/architecture/adr/)
- [API Documentation](docs/api/)
- [User Guides](docs/user-guides/)
- [Deployment Guide](docs/deployment/deployment-guide.md)
- [Troubleshooting Guide](docs/troubleshooting.md)
- [Database Schema](database/schema.sql)

### Related Repositories
- [Frontend Repository](https://github.com/yourusername/frontend)
- [Python Data Service](https://github.com/yourusername/data-service)
- [Infrastructure](https://github.com/yourusername/infrastructure)

### External Resources
- [Go Documentation](https://golang.org/doc/)
- [Gin Framework](https://gin-gonic.com/)
- [PostgreSQL Documentation](https://www.postgresql.org/docs/)
- [FastAPI Documentation](https://fastapi.tiangolo.com/)
- [Angular Documentation](https://angular.io/docs)

---

## ğŸ™ Acknowledgments

- Gin framework team for excellent Go HTTP framework
- FastAPI team for modern Python web framework
- Angular team for robust frontend framework
- PostgreSQL community for reliable database
- Open source community for amazing tools and libraries

---

**Repository:** https://github.com/yourusername/golang-project-product-service

**Last Updated:** February 17, 2026

**Version:** 1.0.0
